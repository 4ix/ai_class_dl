{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.read_csv('./data/wine.csv', header=None)\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 12) (6497,)\n"
     ]
    }
   ],
   "source": [
    "X = wine_df.iloc[:, :-1]\n",
    "y = wine_df.iloc[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wine\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             (None, 30)                390       \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " hidden3 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='wine')\n",
    "model.add(keras.layers.Dense(30, input_shape=(12, ), activation = 'relu', name='hidden1'))\n",
    "model.add(keras.layers.Dense(12, activation = 'relu', name='hidden2'))\n",
    "model.add(keras.layers.Dense(8, activation = 'relu', name='hidden3'))\n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid', name='output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4547, 12) (4547,)\n",
      "(1950, 12) (1950,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1337 - acc: 0.9625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jasper\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.13228, saving model to ./model\\ 1-0.1323.hdf5\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.1491 - acc: 0.9516 - val_loss: 0.1323 - val_acc: 0.9516\n",
      "Epoch 2/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1322 - acc: 0.9550\n",
      "Epoch 2: val_loss improved from 0.13228 to 0.13220, saving model to ./model\\ 2-0.1322.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1355 - acc: 0.9541 - val_loss: 0.1322 - val_acc: 0.9527\n",
      "Epoch 3/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1434 - acc: 0.9425\n",
      "Epoch 3: val_loss improved from 0.13220 to 0.13011, saving model to ./model\\ 3-0.1301.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1356 - acc: 0.9544 - val_loss: 0.1301 - val_acc: 0.9516\n",
      "Epoch 4/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1597 - acc: 0.9375\n",
      "Epoch 4: val_loss did not improve from 0.13011\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1392 - acc: 0.9544 - val_loss: 0.1307 - val_acc: 0.9516\n",
      "Epoch 5/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1242 - acc: 0.9625\n",
      "Epoch 5: val_loss improved from 0.13011 to 0.12908, saving model to ./model\\ 5-0.1291.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1345 - acc: 0.9541 - val_loss: 0.1291 - val_acc: 0.9538\n",
      "Epoch 6/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1338 - acc: 0.9575\n",
      "Epoch 6: val_loss did not improve from 0.12908\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1322 - acc: 0.9549 - val_loss: 0.1296 - val_acc: 0.9538\n",
      "Epoch 7/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1362 - acc: 0.9525\n",
      "Epoch 7: val_loss improved from 0.12908 to 0.12793, saving model to ./model\\ 7-0.1279.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1314 - acc: 0.9557 - val_loss: 0.1279 - val_acc: 0.9527\n",
      "Epoch 8/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0834 - acc: 0.9725\n",
      "Epoch 8: val_loss improved from 0.12793 to 0.12788, saving model to ./model\\ 8-0.1279.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1305 - acc: 0.9544 - val_loss: 0.1279 - val_acc: 0.9538\n",
      "Epoch 9/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1140 - acc: 0.9550\n",
      "Epoch 9: val_loss improved from 0.12788 to 0.12654, saving model to ./model\\ 9-0.1265.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1292 - acc: 0.9560 - val_loss: 0.1265 - val_acc: 0.9538\n",
      "Epoch 10/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1228 - acc: 0.9575\n",
      "Epoch 10: val_loss did not improve from 0.12654\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1296 - acc: 0.9555 - val_loss: 0.1270 - val_acc: 0.9538\n",
      "Epoch 11/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1478 - acc: 0.9575\n",
      "Epoch 11: val_loss improved from 0.12654 to 0.12528, saving model to ./model\\11-0.1253.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1287 - acc: 0.9563 - val_loss: 0.1253 - val_acc: 0.9538\n",
      "Epoch 12/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1034 - acc: 0.9675\n",
      "Epoch 12: val_loss improved from 0.12528 to 0.12446, saving model to ./model\\12-0.1245.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1277 - acc: 0.9566 - val_loss: 0.1245 - val_acc: 0.9538\n",
      "Epoch 13/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1124 - acc: 0.9575\n",
      "Epoch 13: val_loss improved from 0.12446 to 0.12384, saving model to ./model\\13-0.1238.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1285 - acc: 0.9560 - val_loss: 0.1238 - val_acc: 0.9527\n",
      "Epoch 14/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1338 - acc: 0.9550\n",
      "Epoch 14: val_loss improved from 0.12384 to 0.12332, saving model to ./model\\14-0.1233.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1299 - acc: 0.9533 - val_loss: 0.1233 - val_acc: 0.9527\n",
      "Epoch 15/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 15: val_loss improved from 0.12332 to 0.12231, saving model to ./model\\15-0.1223.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1265 - acc: 0.9579 - val_loss: 0.1223 - val_acc: 0.9527\n",
      "Epoch 16/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1317 - acc: 0.9525\n",
      "Epoch 16: val_loss improved from 0.12231 to 0.12135, saving model to ./model\\16-0.1214.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1244 - acc: 0.9566 - val_loss: 0.1214 - val_acc: 0.9527\n",
      "Epoch 17/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0660 - acc: 0.9875\n",
      "Epoch 17: val_loss improved from 0.12135 to 0.12030, saving model to ./model\\17-0.1203.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1241 - acc: 0.9557 - val_loss: 0.1203 - val_acc: 0.9560\n",
      "Epoch 18/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0961 - acc: 0.9675\n",
      "Epoch 18: val_loss improved from 0.12030 to 0.11739, saving model to ./model\\18-0.1174.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1235 - acc: 0.9577 - val_loss: 0.1174 - val_acc: 0.9582\n",
      "Epoch 19/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1064 - acc: 0.9675\n",
      "Epoch 19: val_loss improved from 0.11739 to 0.11400, saving model to ./model\\19-0.1140.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1200 - acc: 0.9585 - val_loss: 0.1140 - val_acc: 0.9593\n",
      "Epoch 20/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1062 - acc: 0.9650\n",
      "Epoch 20: val_loss improved from 0.11400 to 0.11057, saving model to ./model\\20-0.1106.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1176 - acc: 0.9588 - val_loss: 0.1106 - val_acc: 0.9549\n",
      "Epoch 21/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0918 - acc: 0.9725\n",
      "Epoch 21: val_loss improved from 0.11057 to 0.10927, saving model to ./model\\21-0.1093.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1152 - acc: 0.9615 - val_loss: 0.1093 - val_acc: 0.9571\n",
      "Epoch 22/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1319 - acc: 0.9450\n",
      "Epoch 22: val_loss improved from 0.10927 to 0.10747, saving model to ./model\\22-0.1075.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1134 - acc: 0.9604 - val_loss: 0.1075 - val_acc: 0.9670\n",
      "Epoch 23/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1324 - acc: 0.9650\n",
      "Epoch 23: val_loss improved from 0.10747 to 0.10313, saving model to ./model\\23-0.1031.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1107 - acc: 0.9623 - val_loss: 0.1031 - val_acc: 0.9593\n",
      "Epoch 24/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0871 - acc: 0.9700\n",
      "Epoch 24: val_loss improved from 0.10313 to 0.10215, saving model to ./model\\24-0.1021.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1086 - acc: 0.9626 - val_loss: 0.1021 - val_acc: 0.9615\n",
      "Epoch 25/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0855 - acc: 0.9775\n",
      "Epoch 25: val_loss did not improve from 0.10215\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1103 - acc: 0.9599 - val_loss: 0.1055 - val_acc: 0.9681\n",
      "Epoch 26/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1304 - acc: 0.9675\n",
      "Epoch 26: val_loss improved from 0.10215 to 0.10026, saving model to ./model\\26-0.1003.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1073 - acc: 0.9640 - val_loss: 0.1003 - val_acc: 0.9626\n",
      "Epoch 27/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1085 - acc: 0.9650\n",
      "Epoch 27: val_loss improved from 0.10026 to 0.09827, saving model to ./model\\27-0.0983.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1058 - acc: 0.9640 - val_loss: 0.0983 - val_acc: 0.9648\n",
      "Epoch 28/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1366 - acc: 0.9625\n",
      "Epoch 28: val_loss improved from 0.09827 to 0.09674, saving model to ./model\\28-0.0967.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1042 - acc: 0.9659 - val_loss: 0.0967 - val_acc: 0.9637\n",
      "Epoch 29/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0817 - acc: 0.9725\n",
      "Epoch 29: val_loss improved from 0.09674 to 0.09613, saving model to ./model\\29-0.0961.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1034 - acc: 0.9656 - val_loss: 0.0961 - val_acc: 0.9670\n",
      "Epoch 30/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0840 - acc: 0.9725\n",
      "Epoch 30: val_loss did not improve from 0.09613\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1031 - acc: 0.9637 - val_loss: 0.0963 - val_acc: 0.9681\n",
      "Epoch 31/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1081 - acc: 0.9625\n",
      "Epoch 31: val_loss improved from 0.09613 to 0.09425, saving model to ./model\\31-0.0943.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1046 - acc: 0.9651 - val_loss: 0.0943 - val_acc: 0.9615\n",
      "Epoch 32/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1358 - acc: 0.9400\n",
      "Epoch 32: val_loss did not improve from 0.09425\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - acc: 0.9645 - val_loss: 0.0960 - val_acc: 0.9582\n",
      "Epoch 33/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1138 - acc: 0.9550\n",
      "Epoch 33: val_loss improved from 0.09425 to 0.09151, saving model to ./model\\33-0.0915.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1011 - acc: 0.9670 - val_loss: 0.0915 - val_acc: 0.9648\n",
      "Epoch 34/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0974 - acc: 0.9725\n",
      "Epoch 34: val_loss improved from 0.09151 to 0.09029, saving model to ./model\\34-0.0903.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1007 - acc: 0.9648 - val_loss: 0.0903 - val_acc: 0.9681\n",
      "Epoch 35/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0856 - acc: 0.9725\n",
      "Epoch 35: val_loss did not improve from 0.09029\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - acc: 0.9607 - val_loss: 0.0961 - val_acc: 0.9714\n",
      "Epoch 36/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0968 - acc: 0.9750\n",
      "Epoch 36: val_loss improved from 0.09029 to 0.08763, saving model to ./model\\36-0.0876.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0987 - acc: 0.9667 - val_loss: 0.0876 - val_acc: 0.9703\n",
      "Epoch 37/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0781 - acc: 0.9825\n",
      "Epoch 37: val_loss did not improve from 0.08763\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0971 - acc: 0.9689 - val_loss: 0.0882 - val_acc: 0.9681\n",
      "Epoch 38/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0806 - acc: 0.9650\n",
      "Epoch 38: val_loss improved from 0.08763 to 0.08564, saving model to ./model\\38-0.0856.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0953 - acc: 0.9687 - val_loss: 0.0856 - val_acc: 0.9714\n",
      "Epoch 39/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0850 - acc: 0.9800\n",
      "Epoch 39: val_loss did not improve from 0.08564\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0952 - acc: 0.9673 - val_loss: 0.0859 - val_acc: 0.9747\n",
      "Epoch 40/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1086 - acc: 0.9625\n",
      "Epoch 40: val_loss improved from 0.08564 to 0.08355, saving model to ./model\\40-0.0836.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0935 - acc: 0.9722 - val_loss: 0.0836 - val_acc: 0.9725\n",
      "Epoch 41/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0964 - acc: 0.9625\n",
      "Epoch 41: val_loss improved from 0.08355 to 0.08261, saving model to ./model\\41-0.0826.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0925 - acc: 0.9703 - val_loss: 0.0826 - val_acc: 0.9703\n",
      "Epoch 42/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1300 - acc: 0.9650\n",
      "Epoch 42: val_loss improved from 0.08261 to 0.08143, saving model to ./model\\42-0.0814.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0925 - acc: 0.9695 - val_loss: 0.0814 - val_acc: 0.9714\n",
      "Epoch 43/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1047 - acc: 0.9500\n",
      "Epoch 43: val_loss did not improve from 0.08143\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0910 - acc: 0.9709 - val_loss: 0.0832 - val_acc: 0.9648\n",
      "Epoch 44/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0648 - acc: 0.9775\n",
      "Epoch 44: val_loss improved from 0.08143 to 0.08097, saving model to ./model\\44-0.0810.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0949 - acc: 0.9659 - val_loss: 0.0810 - val_acc: 0.9758\n",
      "Epoch 45/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0815 - acc: 0.9825\n",
      "Epoch 45: val_loss did not improve from 0.08097\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0917 - acc: 0.9684 - val_loss: 0.0840 - val_acc: 0.9791\n",
      "Epoch 46/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0751 - acc: 0.9775\n",
      "Epoch 46: val_loss improved from 0.08097 to 0.07848, saving model to ./model\\46-0.0785.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0898 - acc: 0.9703 - val_loss: 0.0785 - val_acc: 0.9714\n",
      "Epoch 47/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1092 - acc: 0.9725\n",
      "Epoch 47: val_loss did not improve from 0.07848\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0885 - acc: 0.9711 - val_loss: 0.0792 - val_acc: 0.9681\n",
      "Epoch 48/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0584 - acc: 0.9800\n",
      "Epoch 48: val_loss improved from 0.07848 to 0.07744, saving model to ./model\\48-0.0774.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0875 - acc: 0.9709 - val_loss: 0.0774 - val_acc: 0.9725\n",
      "Epoch 49/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0778 - acc: 0.9750\n",
      "Epoch 49: val_loss improved from 0.07744 to 0.07605, saving model to ./model\\49-0.0761.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0869 - acc: 0.9703 - val_loss: 0.0761 - val_acc: 0.9736\n",
      "Epoch 50/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0728 - acc: 0.9800\n",
      "Epoch 50: val_loss improved from 0.07605 to 0.07542, saving model to ./model\\50-0.0754.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0862 - acc: 0.9733 - val_loss: 0.0754 - val_acc: 0.9725\n",
      "Epoch 51/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0735 - acc: 0.9825\n",
      "Epoch 51: val_loss did not improve from 0.07542\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0871 - acc: 0.9717 - val_loss: 0.0756 - val_acc: 0.9758\n",
      "Epoch 52/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0874 - acc: 0.9675\n",
      "Epoch 52: val_loss did not improve from 0.07542\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0856 - acc: 0.9725 - val_loss: 0.0755 - val_acc: 0.9780\n",
      "Epoch 53/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0740 - acc: 0.9775\n",
      "Epoch 53: val_loss improved from 0.07542 to 0.07444, saving model to ./model\\53-0.0744.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0836 - acc: 0.9750 - val_loss: 0.0744 - val_acc: 0.9725\n",
      "Epoch 54/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0932 - acc: 0.9725\n",
      "Epoch 54: val_loss improved from 0.07444 to 0.07350, saving model to ./model\\54-0.0735.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0831 - acc: 0.9739 - val_loss: 0.0735 - val_acc: 0.9747\n",
      "Epoch 55/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0680 - acc: 0.9750\n",
      "Epoch 55: val_loss improved from 0.07350 to 0.07349, saving model to ./model\\55-0.0735.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0845 - acc: 0.9733 - val_loss: 0.0735 - val_acc: 0.9714\n",
      "Epoch 56/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1036 - acc: 0.9750\n",
      "Epoch 56: val_loss improved from 0.07349 to 0.07230, saving model to ./model\\56-0.0723.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0815 - acc: 0.9758 - val_loss: 0.0723 - val_acc: 0.9714\n",
      "Epoch 57/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0711 - acc: 0.9750\n",
      "Epoch 57: val_loss improved from 0.07230 to 0.07160, saving model to ./model\\57-0.0716.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0815 - acc: 0.9750 - val_loss: 0.0716 - val_acc: 0.9747\n",
      "Epoch 58/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0807 - acc: 0.9800\n",
      "Epoch 58: val_loss did not improve from 0.07160\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0817 - acc: 0.9747 - val_loss: 0.0724 - val_acc: 0.9714\n",
      "Epoch 59/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0936 - acc: 0.9750\n",
      "Epoch 59: val_loss did not improve from 0.07160\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0802 - acc: 0.9766 - val_loss: 0.0722 - val_acc: 0.9692\n",
      "Epoch 60/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1110 - acc: 0.9650\n",
      "Epoch 60: val_loss improved from 0.07160 to 0.06963, saving model to ./model\\60-0.0696.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0805 - acc: 0.9753 - val_loss: 0.0696 - val_acc: 0.9758\n",
      "Epoch 61/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0778 - acc: 0.9775\n",
      "Epoch 61: val_loss improved from 0.06963 to 0.06938, saving model to ./model\\61-0.0694.hdf5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0782 - acc: 0.9761 - val_loss: 0.0694 - val_acc: 0.9780\n",
      "Epoch 62/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0821 - acc: 0.9700\n",
      "Epoch 62: val_loss did not improve from 0.06938\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0776 - acc: 0.9769 - val_loss: 0.0735 - val_acc: 0.9692\n",
      "Epoch 63/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0771 - acc: 0.9650\n",
      "Epoch 63: val_loss did not improve from 0.06938\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0823 - acc: 0.9722 - val_loss: 0.0710 - val_acc: 0.9703\n",
      "Epoch 64/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0803 - acc: 0.9625\n",
      "Epoch 64: val_loss improved from 0.06938 to 0.06909, saving model to ./model\\64-0.0691.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0818 - acc: 0.9733 - val_loss: 0.0691 - val_acc: 0.9714\n",
      "Epoch 65/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0902 - acc: 0.9725\n",
      "Epoch 65: val_loss improved from 0.06909 to 0.06745, saving model to ./model\\65-0.0674.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0831 - acc: 0.9709 - val_loss: 0.0674 - val_acc: 0.9736\n",
      "Epoch 66/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0993 - acc: 0.9750\n",
      "Epoch 66: val_loss did not improve from 0.06745\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0753 - acc: 0.9777 - val_loss: 0.0677 - val_acc: 0.9791\n",
      "Epoch 67/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0795 - acc: 0.9800\n",
      "Epoch 67: val_loss improved from 0.06745 to 0.06615, saving model to ./model\\67-0.0662.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0752 - acc: 0.9772 - val_loss: 0.0662 - val_acc: 0.9736\n",
      "Epoch 68/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0967 - acc: 0.9750\n",
      "Epoch 68: val_loss did not improve from 0.06615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0777 - acc: 0.9750 - val_loss: 0.0674 - val_acc: 0.9714\n",
      "Epoch 69/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0862 - acc: 0.9775\n",
      "Epoch 69: val_loss did not improve from 0.06615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0781 - acc: 0.9744 - val_loss: 0.0663 - val_acc: 0.9780\n",
      "Epoch 70/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0712 - acc: 0.9800\n",
      "Epoch 70: val_loss improved from 0.06615 to 0.06516, saving model to ./model\\70-0.0652.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0735 - acc: 0.9777 - val_loss: 0.0652 - val_acc: 0.9736\n",
      "Epoch 71/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0740 - acc: 0.9800\n",
      "Epoch 71: val_loss did not improve from 0.06516\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0743 - acc: 0.9780 - val_loss: 0.0693 - val_acc: 0.9769\n",
      "Epoch 72/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0899 - acc: 0.9675\n",
      "Epoch 72: val_loss did not improve from 0.06516\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0764 - acc: 0.9761 - val_loss: 0.0654 - val_acc: 0.9791\n",
      "Epoch 73/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0827 - acc: 0.9800\n",
      "Epoch 73: val_loss did not improve from 0.06516\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0721 - acc: 0.9791 - val_loss: 0.0667 - val_acc: 0.9725\n",
      "Epoch 74/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1001 - acc: 0.9750\n",
      "Epoch 74: val_loss did not improve from 0.06516\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0788 - acc: 0.9753 - val_loss: 0.0659 - val_acc: 0.9714\n",
      "Epoch 75/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0793 - acc: 0.9775\n",
      "Epoch 75: val_loss did not improve from 0.06516\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0716 - acc: 0.9783 - val_loss: 0.0678 - val_acc: 0.9736\n",
      "Epoch 76/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0550 - acc: 0.9775\n",
      "Epoch 76: val_loss improved from 0.06516 to 0.06284, saving model to ./model\\76-0.0628.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0777 - acc: 0.9744 - val_loss: 0.0628 - val_acc: 0.9791\n",
      "Epoch 77/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0743 - acc: 0.9675\n",
      "Epoch 77: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0731 - acc: 0.9766 - val_loss: 0.0790 - val_acc: 0.9758\n",
      "Epoch 78/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1045 - acc: 0.9575\n",
      "Epoch 78: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0789 - acc: 0.9733 - val_loss: 0.0674 - val_acc: 0.9769\n",
      "Epoch 79/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0720 - acc: 0.9775\n",
      "Epoch 79: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0731 - acc: 0.9766 - val_loss: 0.0726 - val_acc: 0.9780\n",
      "Epoch 80/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0857 - acc: 0.9775\n",
      "Epoch 80: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0819 - acc: 0.9725 - val_loss: 0.0631 - val_acc: 0.9736\n",
      "Epoch 81/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0535 - acc: 0.9800\n",
      "Epoch 81: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0719 - acc: 0.9769 - val_loss: 0.0749 - val_acc: 0.9725\n",
      "Epoch 82/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0697 - acc: 0.9750\n",
      "Epoch 82: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - acc: 0.9769 - val_loss: 0.0636 - val_acc: 0.9802\n",
      "Epoch 83/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0859 - acc: 0.9750\n",
      "Epoch 83: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0695 - acc: 0.9775 - val_loss: 0.0636 - val_acc: 0.9758\n",
      "Epoch 84/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0878 - acc: 0.9800\n",
      "Epoch 84: val_loss did not improve from 0.06284\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0685 - acc: 0.9791 - val_loss: 0.0657 - val_acc: 0.9769\n",
      "Epoch 85/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0785 - acc: 0.9750\n",
      "Epoch 85: val_loss improved from 0.06284 to 0.06070, saving model to ./model\\85-0.0607.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0699 - acc: 0.9802 - val_loss: 0.0607 - val_acc: 0.9802\n",
      "Epoch 86/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0541 - acc: 0.9850\n",
      "Epoch 86: val_loss improved from 0.06070 to 0.06036, saving model to ./model\\86-0.0604.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0772 - acc: 0.9753 - val_loss: 0.0604 - val_acc: 0.9747\n",
      "Epoch 87/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0613 - acc: 0.9800\n",
      "Epoch 87: val_loss did not improve from 0.06036\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0685 - acc: 0.9794 - val_loss: 0.0777 - val_acc: 0.9692\n",
      "Epoch 88/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0900 - acc: 0.9550\n",
      "Epoch 88: val_loss improved from 0.06036 to 0.05933, saving model to ./model\\88-0.0593.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0731 - acc: 0.9753 - val_loss: 0.0593 - val_acc: 0.9769\n",
      "Epoch 89/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0847 - acc: 0.9750\n",
      "Epoch 89: val_loss improved from 0.05933 to 0.05888, saving model to ./model\\89-0.0589.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0659 - acc: 0.9799 - val_loss: 0.0589 - val_acc: 0.9769\n",
      "Epoch 90/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0628 - acc: 0.9750\n",
      "Epoch 90: val_loss did not improve from 0.05888\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0652 - acc: 0.9805 - val_loss: 0.0684 - val_acc: 0.9780\n",
      "Epoch 91/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0709 - acc: 0.9750\n",
      "Epoch 91: val_loss did not improve from 0.05888\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0738 - acc: 0.9775 - val_loss: 0.0680 - val_acc: 0.9780\n",
      "Epoch 92/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0931 - acc: 0.9700\n",
      "Epoch 92: val_loss did not improve from 0.05888\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0727 - acc: 0.9775 - val_loss: 0.0598 - val_acc: 0.9791\n",
      "Epoch 93/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0845 - acc: 0.9800\n",
      "Epoch 93: val_loss improved from 0.05888 to 0.05881, saving model to ./model\\93-0.0588.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0673 - acc: 0.9788 - val_loss: 0.0588 - val_acc: 0.9758\n",
      "Epoch 94/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0690 - acc: 0.9675\n",
      "Epoch 94: val_loss improved from 0.05881 to 0.05856, saving model to ./model\\94-0.0586.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0662 - acc: 0.9791 - val_loss: 0.0586 - val_acc: 0.9791\n",
      "Epoch 95/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0611 - acc: 0.9750\n",
      "Epoch 95: val_loss improved from 0.05856 to 0.05733, saving model to ./model\\95-0.0573.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0727 - acc: 0.9769 - val_loss: 0.0573 - val_acc: 0.9813\n",
      "Epoch 96/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0629 - acc: 0.9825\n",
      "Epoch 96: val_loss did not improve from 0.05733\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0665 - acc: 0.9791 - val_loss: 0.0606 - val_acc: 0.9758\n",
      "Epoch 97/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0730 - acc: 0.9875\n",
      "Epoch 97: val_loss did not improve from 0.05733\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0640 - acc: 0.9810 - val_loss: 0.0573 - val_acc: 0.9780\n",
      "Epoch 98/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0424 - acc: 0.9825\n",
      "Epoch 98: val_loss improved from 0.05733 to 0.05694, saving model to ./model\\98-0.0569.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0638 - acc: 0.9805 - val_loss: 0.0569 - val_acc: 0.9780\n",
      "Epoch 99/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0588 - acc: 0.9775\n",
      "Epoch 99: val_loss improved from 0.05694 to 0.05685, saving model to ./model\\99-0.0568.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0643 - acc: 0.9816 - val_loss: 0.0568 - val_acc: 0.9780\n",
      "Epoch 100/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0641 - acc: 0.9775\n",
      "Epoch 100: val_loss did not improve from 0.05685\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0642 - acc: 0.9802 - val_loss: 0.0586 - val_acc: 0.9802\n",
      "Epoch 101/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0650 - acc: 0.9750\n",
      "Epoch 101: val_loss improved from 0.05685 to 0.05618, saving model to ./model\\101-0.0562.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0646 - acc: 0.9791 - val_loss: 0.0562 - val_acc: 0.9780\n",
      "Epoch 102/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0765 - acc: 0.9750\n",
      "Epoch 102: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0632 - acc: 0.9819 - val_loss: 0.0575 - val_acc: 0.9802\n",
      "Epoch 103/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0414 - acc: 0.9950\n",
      "Epoch 103: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0683 - acc: 0.9769 - val_loss: 0.0571 - val_acc: 0.9802\n",
      "Epoch 104/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0715 - acc: 0.9800\n",
      "Epoch 104: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - acc: 0.9758 - val_loss: 0.0584 - val_acc: 0.9802\n",
      "Epoch 105/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0399 - acc: 0.9875\n",
      "Epoch 105: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0645 - acc: 0.9799 - val_loss: 0.0628 - val_acc: 0.9791\n",
      "Epoch 106/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0562 - acc: 0.9925\n",
      "Epoch 106: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0644 - acc: 0.9816 - val_loss: 0.0602 - val_acc: 0.9791\n",
      "Epoch 107/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0349 - acc: 0.9925\n",
      "Epoch 107: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0730 - acc: 0.9783 - val_loss: 0.0600 - val_acc: 0.9791\n",
      "Epoch 108/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0780 - acc: 0.9750\n",
      "Epoch 108: val_loss did not improve from 0.05618\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0660 - acc: 0.9805 - val_loss: 0.0757 - val_acc: 0.9725\n",
      "Epoch 109/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0562 - acc: 0.9800\n",
      "Epoch 109: val_loss improved from 0.05618 to 0.05585, saving model to ./model\\109-0.0559.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0666 - acc: 0.9797 - val_loss: 0.0559 - val_acc: 0.9813\n",
      "Epoch 110/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0600 - acc: 0.9725\n",
      "Epoch 110: val_loss did not improve from 0.05585\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0633 - acc: 0.9797 - val_loss: 0.0631 - val_acc: 0.9802\n",
      "Epoch 111/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0500 - acc: 0.9925\n",
      "Epoch 111: val_loss improved from 0.05585 to 0.05496, saving model to ./model\\111-0.0550.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0622 - acc: 0.9827 - val_loss: 0.0550 - val_acc: 0.9802\n",
      "Epoch 112/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0738 - acc: 0.9825\n",
      "Epoch 112: val_loss did not improve from 0.05496\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0606 - acc: 0.9830 - val_loss: 0.0552 - val_acc: 0.9769\n",
      "Epoch 113/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0530 - acc: 0.9825\n",
      "Epoch 113: val_loss did not improve from 0.05496\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0611 - acc: 0.9832 - val_loss: 0.0581 - val_acc: 0.9791\n",
      "Epoch 114/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0847 - acc: 0.9725\n",
      "Epoch 114: val_loss did not improve from 0.05496\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0623 - acc: 0.9821 - val_loss: 0.0600 - val_acc: 0.9780\n",
      "Epoch 115/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0414 - acc: 0.9875\n",
      "Epoch 115: val_loss did not improve from 0.05496\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0621 - acc: 0.9810 - val_loss: 0.0579 - val_acc: 0.9791\n",
      "Epoch 116/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0690 - acc: 0.9850\n",
      "Epoch 116: val_loss improved from 0.05496 to 0.05412, saving model to ./model\\116-0.0541.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0628 - acc: 0.9810 - val_loss: 0.0541 - val_acc: 0.9802\n",
      "Epoch 117/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0939 - acc: 0.9675\n",
      "Epoch 117: val_loss improved from 0.05412 to 0.05404, saving model to ./model\\117-0.0540.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0606 - acc: 0.9816 - val_loss: 0.0540 - val_acc: 0.9824\n",
      "Epoch 118/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0410 - acc: 0.9875\n",
      "Epoch 118: val_loss improved from 0.05404 to 0.05395, saving model to ./model\\118-0.0539.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0602 - acc: 0.9824 - val_loss: 0.0539 - val_acc: 0.9835\n",
      "Epoch 119/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0745 - acc: 0.9800\n",
      "Epoch 119: val_loss did not improve from 0.05395\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0594 - acc: 0.9830 - val_loss: 0.0545 - val_acc: 0.9824\n",
      "Epoch 120/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0515 - acc: 0.9725\n",
      "Epoch 120: val_loss improved from 0.05395 to 0.05360, saving model to ./model\\120-0.0536.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0602 - acc: 0.9819 - val_loss: 0.0536 - val_acc: 0.9802\n",
      "Epoch 121/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0618 - acc: 0.9750\n",
      "Epoch 121: val_loss did not improve from 0.05360\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0653 - acc: 0.9794 - val_loss: 0.0536 - val_acc: 0.9824\n",
      "Epoch 122/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0522 - acc: 0.9825\n",
      "Epoch 122: val_loss did not improve from 0.05360\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0602 - acc: 0.9819 - val_loss: 0.0544 - val_acc: 0.9813\n",
      "Epoch 123/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0953 - acc: 0.9800\n",
      "Epoch 123: val_loss improved from 0.05360 to 0.05273, saving model to ./model\\123-0.0527.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0592 - acc: 0.9849 - val_loss: 0.0527 - val_acc: 0.9824\n",
      "Epoch 124/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0561 - acc: 0.9875\n",
      "Epoch 124: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0596 - acc: 0.9830 - val_loss: 0.0537 - val_acc: 0.9824\n",
      "Epoch 125/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0525 - acc: 0.9875\n",
      "Epoch 125: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0609 - acc: 0.9805 - val_loss: 0.0567 - val_acc: 0.9813\n",
      "Epoch 126/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0420 - acc: 0.9925\n",
      "Epoch 126: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0595 - acc: 0.9841 - val_loss: 0.0608 - val_acc: 0.9791\n",
      "Epoch 127/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0389 - acc: 0.9875\n",
      "Epoch 127: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0634 - acc: 0.9810 - val_loss: 0.0739 - val_acc: 0.9769\n",
      "Epoch 128/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0312 - acc: 0.9925\n",
      "Epoch 128: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0802 - acc: 0.9742 - val_loss: 0.0558 - val_acc: 0.9835\n",
      "Epoch 129/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0534 - acc: 0.9825\n",
      "Epoch 129: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0635 - acc: 0.9810 - val_loss: 0.0582 - val_acc: 0.9813\n",
      "Epoch 130/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1032 - acc: 0.9650\n",
      "Epoch 130: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0593 - acc: 0.9821 - val_loss: 0.0644 - val_acc: 0.9791\n",
      "Epoch 131/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1005 - acc: 0.9675\n",
      "Epoch 131: val_loss did not improve from 0.05273\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0662 - acc: 0.9799 - val_loss: 0.0548 - val_acc: 0.9824\n",
      "Epoch 132/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0740 - acc: 0.9800\n",
      "Epoch 132: val_loss improved from 0.05273 to 0.05258, saving model to ./model\\132-0.0526.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0655 - acc: 0.9791 - val_loss: 0.0526 - val_acc: 0.9835\n",
      "Epoch 133/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0743 - acc: 0.9825\n",
      "Epoch 133: val_loss did not improve from 0.05258\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0647 - acc: 0.9794 - val_loss: 0.0591 - val_acc: 0.9791\n",
      "Epoch 134/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0778 - acc: 0.9625\n",
      "Epoch 134: val_loss improved from 0.05258 to 0.05214, saving model to ./model\\134-0.0521.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0602 - acc: 0.9808 - val_loss: 0.0521 - val_acc: 0.9824\n",
      "Epoch 135/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0515 - acc: 0.9850\n",
      "Epoch 135: val_loss did not improve from 0.05214\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0587 - acc: 0.9819 - val_loss: 0.0637 - val_acc: 0.9791\n",
      "Epoch 136/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0849 - acc: 0.9650\n",
      "Epoch 136: val_loss did not improve from 0.05214\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0608 - acc: 0.9797 - val_loss: 0.0567 - val_acc: 0.9802\n",
      "Epoch 137/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0482 - acc: 0.9775\n",
      "Epoch 137: val_loss did not improve from 0.05214\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0610 - acc: 0.9816 - val_loss: 0.0582 - val_acc: 0.9824\n",
      "Epoch 138/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0578 - acc: 0.9875\n",
      "Epoch 138: val_loss did not improve from 0.05214\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0598 - acc: 0.9843 - val_loss: 0.0551 - val_acc: 0.9813\n",
      "Epoch 139/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0498 - acc: 0.9900\n",
      "Epoch 139: val_loss improved from 0.05214 to 0.05137, saving model to ./model\\139-0.0514.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0612 - acc: 0.9824 - val_loss: 0.0514 - val_acc: 0.9813\n",
      "Epoch 140/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0733 - acc: 0.9775\n",
      "Epoch 140: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0570 - acc: 0.9830 - val_loss: 0.0562 - val_acc: 0.9791\n",
      "Epoch 141/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0501 - acc: 0.9850\n",
      "Epoch 141: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0580 - acc: 0.9832 - val_loss: 0.0517 - val_acc: 0.9835\n",
      "Epoch 142/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0823 - acc: 0.9725\n",
      "Epoch 142: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0563 - acc: 0.9832 - val_loss: 0.0515 - val_acc: 0.9824\n",
      "Epoch 143/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0309 - acc: 0.9925\n",
      "Epoch 143: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0562 - acc: 0.9830 - val_loss: 0.0516 - val_acc: 0.9824\n",
      "Epoch 144/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0698 - acc: 0.9825\n",
      "Epoch 144: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0561 - acc: 0.9832 - val_loss: 0.0525 - val_acc: 0.9813\n",
      "Epoch 145/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0823 - acc: 0.9825\n",
      "Epoch 145: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0584 - acc: 0.9824 - val_loss: 0.0552 - val_acc: 0.9802\n",
      "Epoch 146/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0852 - acc: 0.9750\n",
      "Epoch 146: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0578 - acc: 0.9849 - val_loss: 0.0611 - val_acc: 0.9791\n",
      "Epoch 147/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0468 - acc: 0.9875\n",
      "Epoch 147: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0602 - acc: 0.9827 - val_loss: 0.0523 - val_acc: 0.9835\n",
      "Epoch 148/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0643 - acc: 0.9700\n",
      "Epoch 148: val_loss did not improve from 0.05137\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0564 - acc: 0.9835 - val_loss: 0.0533 - val_acc: 0.9835\n",
      "Epoch 149/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0419 - acc: 0.9850\n",
      "Epoch 149: val_loss improved from 0.05137 to 0.05022, saving model to ./model\\149-0.0502.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0564 - acc: 0.9841 - val_loss: 0.0502 - val_acc: 0.9824\n",
      "Epoch 150/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0824 - acc: 0.9675\n",
      "Epoch 150: val_loss did not improve from 0.05022\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0641 - val_acc: 0.9802\n",
      "Epoch 151/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1064 - acc: 0.9775\n",
      "Epoch 151: val_loss did not improve from 0.05022\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0598 - acc: 0.9821 - val_loss: 0.0508 - val_acc: 0.9813\n",
      "Epoch 152/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0549 - acc: 0.9900\n",
      "Epoch 152: val_loss did not improve from 0.05022\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0551 - acc: 0.9841 - val_loss: 0.0512 - val_acc: 0.9835\n",
      "Epoch 153/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0375 - acc: 0.9825\n",
      "Epoch 153: val_loss did not improve from 0.05022\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0556 - acc: 0.9832 - val_loss: 0.0504 - val_acc: 0.9824\n",
      "Epoch 154/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0573 - acc: 0.9875\n",
      "Epoch 154: val_loss improved from 0.05022 to 0.04970, saving model to ./model\\154-0.0497.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0553 - acc: 0.9838 - val_loss: 0.0497 - val_acc: 0.9813\n",
      "Epoch 155/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0653 - acc: 0.9800\n",
      "Epoch 155: val_loss improved from 0.04970 to 0.04970, saving model to ./model\\155-0.0497.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0548 - acc: 0.9843 - val_loss: 0.0497 - val_acc: 0.9813\n",
      "Epoch 156/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0594 - acc: 0.9875\n",
      "Epoch 156: val_loss did not improve from 0.04970\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0565 - acc: 0.9838 - val_loss: 0.0522 - val_acc: 0.9835\n",
      "Epoch 157/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0677 - acc: 0.9775\n",
      "Epoch 157: val_loss did not improve from 0.04970\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0553 - acc: 0.9854 - val_loss: 0.0503 - val_acc: 0.9824\n",
      "Epoch 158/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0703 - acc: 0.9725\n",
      "Epoch 158: val_loss did not improve from 0.04970\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0549 - acc: 0.9838 - val_loss: 0.0510 - val_acc: 0.9824\n",
      "Epoch 159/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0496 - acc: 0.9800\n",
      "Epoch 159: val_loss improved from 0.04970 to 0.04962, saving model to ./model\\159-0.0496.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0548 - acc: 0.9849 - val_loss: 0.0496 - val_acc: 0.9824\n",
      "Epoch 160/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0292 - acc: 0.9900\n",
      "Epoch 160: val_loss did not improve from 0.04962\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0544 - acc: 0.9841 - val_loss: 0.0521 - val_acc: 0.9846\n",
      "Epoch 161/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0367 - acc: 0.9900\n",
      "Epoch 161: val_loss did not improve from 0.04962\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0557 - acc: 0.9830 - val_loss: 0.0512 - val_acc: 0.9846\n",
      "Epoch 162/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0624 - acc: 0.9775\n",
      "Epoch 162: val_loss did not improve from 0.04962\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0547 - acc: 0.9846 - val_loss: 0.0501 - val_acc: 0.9835\n",
      "Epoch 163/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0553 - acc: 0.9825\n",
      "Epoch 163: val_loss improved from 0.04962 to 0.04916, saving model to ./model\\163-0.0492.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0557 - acc: 0.9849 - val_loss: 0.0492 - val_acc: 0.9824\n",
      "Epoch 164/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0390 - acc: 0.9850\n",
      "Epoch 164: val_loss did not improve from 0.04916\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0550 - acc: 0.9841 - val_loss: 0.0500 - val_acc: 0.9835\n",
      "Epoch 165/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0860 - acc: 0.9725\n",
      "Epoch 165: val_loss did not improve from 0.04916\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0561 - val_acc: 0.9802\n",
      "Epoch 166/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0723 - acc: 0.9725\n",
      "Epoch 166: val_loss did not improve from 0.04916\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0576 - acc: 0.9827 - val_loss: 0.0584 - val_acc: 0.9791\n",
      "Epoch 167/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0462 - acc: 0.9825\n",
      "Epoch 167: val_loss did not improve from 0.04916\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - acc: 0.9816 - val_loss: 0.0516 - val_acc: 0.9813\n",
      "Epoch 168/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0796 - acc: 0.9800\n",
      "Epoch 168: val_loss did not improve from 0.04916\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0543 - acc: 0.9852 - val_loss: 0.0498 - val_acc: 0.9813\n",
      "Epoch 169/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0546 - acc: 0.9825\n",
      "Epoch 169: val_loss improved from 0.04916 to 0.04876, saving model to ./model\\169-0.0488.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0559 - acc: 0.9835 - val_loss: 0.0488 - val_acc: 0.9824\n",
      "Epoch 170/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0358 - acc: 0.9925\n",
      "Epoch 170: val_loss did not improve from 0.04876\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0553 - acc: 0.9821 - val_loss: 0.0495 - val_acc: 0.9813\n",
      "Epoch 171/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0887 - acc: 0.9750\n",
      "Epoch 171: val_loss improved from 0.04876 to 0.04791, saving model to ./model\\171-0.0479.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0479 - val_acc: 0.9824\n",
      "Epoch 172/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0891 - acc: 0.9825\n",
      "Epoch 172: val_loss did not improve from 0.04791\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0535 - acc: 0.9868 - val_loss: 0.0481 - val_acc: 0.9846\n",
      "Epoch 173/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0725 - acc: 0.9750\n",
      "Epoch 173: val_loss improved from 0.04791 to 0.04762, saving model to ./model\\173-0.0476.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0538 - acc: 0.9838 - val_loss: 0.0476 - val_acc: 0.9824\n",
      "Epoch 174/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0396 - acc: 0.9900\n",
      "Epoch 174: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0540 - acc: 0.9852 - val_loss: 0.0480 - val_acc: 0.9846\n",
      "Epoch 175/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0620 - acc: 0.9825\n",
      "Epoch 175: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0537 - acc: 0.9860 - val_loss: 0.0477 - val_acc: 0.9835\n",
      "Epoch 176/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0305 - acc: 0.9925\n",
      "Epoch 176: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - acc: 0.9843 - val_loss: 0.0563 - val_acc: 0.9791\n",
      "Epoch 177/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1143 - acc: 0.9650\n",
      "Epoch 177: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0556 - acc: 0.9819 - val_loss: 0.0482 - val_acc: 0.9813\n",
      "Epoch 178/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0852 - acc: 0.9775\n",
      "Epoch 178: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0542 - acc: 0.9846 - val_loss: 0.0480 - val_acc: 0.9835\n",
      "Epoch 179/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0633 - acc: 0.9825\n",
      "Epoch 179: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0552 - acc: 0.9854 - val_loss: 0.0486 - val_acc: 0.9835\n",
      "Epoch 180/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0414 - acc: 0.9925\n",
      "Epoch 180: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0549 - acc: 0.9841 - val_loss: 0.0490 - val_acc: 0.9813\n",
      "Epoch 181/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0625 - acc: 0.9800\n",
      "Epoch 181: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0533 - acc: 0.9843 - val_loss: 0.0489 - val_acc: 0.9835\n",
      "Epoch 182/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0404 - acc: 0.9850\n",
      "Epoch 182: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0535 - acc: 0.9852 - val_loss: 0.0506 - val_acc: 0.9802\n",
      "Epoch 183/200\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0524 - acc: 0.9900\n",
      "Epoch 183: val_loss did not improve from 0.04762\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0565 - acc: 0.9827 - val_loss: 0.0500 - val_acc: 0.9813\n"
     ]
    }
   ],
   "source": [
    "model_path = './model/{epoch:2d}-{val_loss:.4f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=400, validation_split=0.2, verbose=1, callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/step - loss: 0.0678 - acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0677850991487503, 0.9810256361961365]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVbElEQVR4nO3dd3gUVRcG8Hc3vRJKSAIEQu81IAICghKkIxakI+InggUQFEQUsGAXLIBSxIagUixEJUivIhCkRGoglEAIJCQhIXW+P05mZzfZ9E12k31/z5NnZmdnZ+9ko3s499x7dYqiKCAiIiKyI3prN4CIiIiorDEAIiIiIrvDAIiIiIjsDgMgIiIisjsMgIiIiMjuMAAiIiIiu8MAiIiIiOyOo7UbYIuysrJw5coVeHl5QafTWbs5REREVAiKoiAxMRE1atSAXp9/jocBkBlXrlxBYGCgtZtBRERExXDx4kXUqlUr33MYAJnh5eUFQH6B3t7eFr12eno6Nm3ahJCQEDg5OVn02raM9837tge8b/u5b3u8Z8D27zshIQGBgYGG7/H8MAAyQ+328vb2LpUAyN3dHd7e3jb5x1NaeN+8b3vA+7af+7bHewbKz30XpnyFRdBERERkdxgAERERkd1hAERERER2hzVARERkcVlZWUhLS7N2M0pNeno6HB0dcefOHWRmZlq7OWXGFu7b2dm5wCHuhcEAiIiILCotLQ2RkZHIysqydlNKjaIo8Pf3x8WLF+1qvjhbuG+9Xo+6devC2dm5RNdhAERERBajKAqio6Ph4OCAwMBAi/xL3RZlZWUhKSkJnp6eFfYezbH2fasTFUdHR6N27dolCsIYABERkcVkZGQgOTkZNWrUgLu7u7WbU2rULj5XV1e7C4Csfd++vr64cuUKMjIySjQU334+NSIiKnVqXUhJuyeI8qL+bZW0BokBEBERWZw91cVQ2bLU3xYDICIiIrI7DICIiIjI7jAAIiIisrCgoCAsWLDA6tegvHEUWFlKTwcuX4bbtWvWbgkRERm599570aZNG4sFHAcOHICHh4dFrkWlgxmgsrRnD5zq1kWn11+3dkuIiKiIFEVBRkZGoc719fWt0NMAVAQMgMqStzcAwDE52coNISIqI4oC3L5tnR9FKVQTx44di+3bt2PhwoXQ6XTQ6XQ4f/48tm3bBp1Ohz///BPt27eHi4sLdu7cibNnz2Lw4MFo1KgRvL290aFDB2zevNnkmjm7r3Q6HZYtW4YHH3wQ7u7uaNiwIX755Zci/SqjoqIwaNAgeHp6wtvbG48++iiuGfUoHDlyBD169ICXlxe8vb0RHByMf/75BwBw4cIFDBgwAJUrV4aHhweaN2+O0NDQIr1/RcMusLJUqRIAwCk5GYX7z5KIqJxLTgY8Pa3z3klJQCG6oRYuXIhTp06hRYsWmDdvHgDJ4Jw/fx4A8OKLL+L9999HvXr14OPjg0uXLqFPnz546aWXUK1aNXzzzTcYMGAATp48idq1a+f5PnPnzsW7776L9957D5988glGjBiBCxcuoEqVKgW2UVEUDB48GB4eHti+fTsyMjIwceJEDB06FNu2bQMAjBgxAm3btsXixYvh4OCA8PBww0SBkyZNQlpaGnbs2AEPDw+cOHECntb6XGwEA6CypGaA7txBemYmUIIZLImIyDIqVaoEZ2dnuLu7w9/fP9fz8+bNQ69evQyPq1atipYtWyIhIQHe3t544403sH79evzyyy945pln8nyfsWPHYtiwYQCAt956C5988gn+/vtvPPDAAwW2cfPmzfj3338RGRmJwMBAAMA333yD5s2b48CBA+jQoQOioqIwffp0NGnSBADQsGFDw+ujoqLw0EMPoWXLlgCAevXqFeI3U7ExACpLXl7afmIi4OpqvbYQEZUFd3fJxFjrvS2gffv2Jo9v376NOXPm4Ndff8XVq1eRkZGBlJQUREVF5XudVq1aGfY9PDzg5eWFmJiYQrUhIiICgYGBhuAHAJo1awYfHx9ERESgQ4cOmDp1KsaPH49vvvkG999/Px555BHUr18fAPDcc8/h6aefxqZNm3D//ffjoYceMmmPPWINUFlycYHi4iL7CQnWbQsRUVnQ6aQbyho/FpoxOOdorunTp2PdunV45ZVXsH37doSHh6Nly5ZIS0vL9zo5163S6XTIysoqVBsURTE7A7Lx8Tlz5uD48ePo168ftmzZgmbNmmH9+vUAgPHjx+PcuXMYNWoUjh49ivbt2+OTTz4p1HtXVAyAylp2NxgDICIi2+Hs7FzotaV27tyJMWPGoH///mjZsiX8/f0N9UKlpVmzZoiKisLFixcNx06cOIFbt26hadOmhmONGjXClClTsGnTJgwZMgRffvml4bnAwEBMmDAB69atwwsvvIClS5eWapttHQOgspYdAOkSE63cECIiUgUFBWH//v04f/48YmNj883MNGjQAOvXr8fRo0dx5MgRDB8+vNCZnOK6//770apVK4wYMQKHDh3C33//jdGjR6N79+5o3749UlJS8Mwzz2Dbtm24cOECdu/ejQMHDhiCo8mTJ+PPP/9EZGQkDh06hC1btpgETvaIAVBZU+uAmAEiIrIZ06ZNg4ODA5o1awZfX99863k++ugjVK5cGb1798agQYPQu3dvtGvXrlTbp9PpsGHDBlSuXBndunXD/fffj3r16mHNmjUAAAcHB9y4cQOjR49Go0aN8Oijj6JPnz6YO3cuAFk5fdKkSWjatCkeeOABNG7cGIsWLSrVNts6FkGXMcXbGzqAARARkQ1p1KgR9u7da3IsKCgIipm5hIKCgrB582bDKDC9Xo9JkyaZnJOzS8zcdeLj4/NtU85r1K5dGz///LPZc52dnfH999/neS17r/cxhxmgsqZmgNgFRkREZDUMgMpa9mSIOmaAiIiIrIYBUBlTOAqMiIjI6hgAlTUWQRMREVkdA6Cypg6DZwBERERkNQyAyhq7wIiIiKyOAVAZUzgKjIiIyOoYAJU1ZoCIiIisjgFQWWMNEBFRhRQUFIQFCxYYHquzNwMyqaFOp0N4eHier9+2bRt0Ol2BEyQWxFLXKci9996LyZMnl+p7lCbOBF3GDMPg2QVGRFShHDhwINfK8arAwEBER0ejWrVqFn3Pe++9F23atDEJvDp37ozo6GhUyp53jsxjAFTWOAyeiKhC8vX1zfM5BwcH+Pv7l0k7nJ2dy+y9yjN2gZU1NSJPTARKefVgIiIq2Oeff46aNWvmWtF94MCBGDNmDADg7NmzGDRoEPz8/ODp6YmOHTti27ZtJufn7AIzZq4LLDQ0FI0aNYKbmxt69OiRa+2vGzduYNiwYahVqxbc3d3RsmVLk/W+xo4di+3bt2PhwoXQ6XTQ6XQ4f/682S6wtWvXonnz5nBxcUFQUBA++OCDXG1/6623MG7cOHh5eaF27dr44osvCvcLzBYXF4fRo0ejcuXKcHd3R58+fXD69GnD8xcuXMCAAQNQuXJleHh4oHnz5ggNDTW8dsSIEfD19YWbmxsaNmyIL7/8skjvX1QMgMqaWgOkKEBSkpUbQ0RUuhQFuH3bOj9m1h8165FHHkFsbCy2bt1qOBYXF4c///wTI0aMAAAkJSWhb9++2Lx5Mw4fPoyQkBAMGzYs31Xj83Px4kUMGTIEffv2RXh4OMaPH48ZM2aYnHPnzh0EBwfjt99+w7Fjx/C///0Po0aNwv79+wEACxcuRKdOnfDkk08iOjoa0dHRCAwMzPVeBw8exKOPPorHHnsMR48exZw5czB79mysXLnS5LwPPvgA7du3x+HDhzFx4kQ8/fTT+O+//wp9T2PHjsU///yDX375BXv37oWiKOjbty/S09MBAJMmTUJqaip27NiBo0eP4p133oGnpycAYPbs2Thx4gR+//13REREYPHixRbvLsyJXWBlzcUFWY6O0GdkSDeYWhNERFQBJScD2d9xZS4pCcijJMdElSpV8MADD2DVqlW47777AAA//vgjqlSpYnjcunVrtG7d2vCa119/HevWrcOvv/6KZ599tshtW7x4MerVq4ePPvoIOp0OjRs3NgQFqpo1a2LatGmGx88++yz++OMP/Pjjj+jYsSMqVaoEZ2dnuLu759vl9eGHH+K+++7D7NmzAcjK9ydOnMB7772HsWPHGs7r27cvJk6cCAB46aWX8NFHH2Hbtm1o0qRJgfdz+vRp/PLLL9i9ezc6d+4MAPjuu+8QGBiIDRs24JFHHkFUVBQeeughtGzZEgBQr149w+ujoqLQtm1btG/fHoBkpEobM0BlTadDupub7LMOiIjIJowYMQJr165FamoqAPnyfuyxx+Dg4AAAuH37Nl588UU0a9YMPj4+8Pb2xqlTp4qdAYqIiMDdd98NnU5nONapUyeTczIzM/Hmm2+iVatWqFq1Kjw9PbFp06Yiv2dERAS6dOlicqxLly44ffo0MjMzDcdatWpl2NfpdPD390dMTEyh38PR0REdO3Y0HKtatSoaN26MiIgIAMBzzz2HN954A126dMFrr72Gf//913Du008/jdWrV6NNmzZ48cUXsWfPniLdY3EwALKCDHd32WEAREQVnLu7ZGKs8aP+r7YwBgwYgKysLGzcuBEXL17Ezp07MXLkSMPz06dPx9q1a/Hmm29i586dOHToEJo1a4a0tLRi/V6UQvTPffDBB/joo4/w4osvYsuWLQgPD0fv3r2L/J6KopgEWnm9v5OTk8ljnU6Xqy4qv/co6L3Hjx+Pc+fOYdSoUTh69Cjat2+PTz75BADQp08fXLhwAZMnT8aVK1dw3333mWS/SgO7wKwggxkgIrITOl3huqGszc3NDUOGDMF3332HM2fOoFGjRggODjY8v3PnTowdOxYPPvggACAhIaHY2R8AaNasmWGOINW+fftMHu/cuRODBg0yBGJZWVk4ffo0mjZtajjH2dnZJIuT13vt2rXL5NiePXvQqFEjQ4arpJo1a4aMjAzs37/f0AV248YNnDp1yqS9gYGBmDBhAiZMmICZM2di6dKlhi5EX19fjB07FmPHjkXXrl0xffp0vP/++xZpnzlWzwAtWrQIdevWhaurK4KDg7Fz5848z42Ojsbw4cPRuHFj6PX6AidgWr16NXQ6HQYPHmzZRpdQOjNAREQ2Z8SIEdi4cSNWrFhhkv0BgAYNGmDdunUIDw/HkSNHMGLEiEJlcfIyYcIEnD17FlOnTsXJkyexatWqXEXJDRo0QFhYGPbs2YOIiAg89dRTuHr1qsk5QUFB2L9/P86fP4/Y2FizGZsXXngBf/31F15//XWcOnUKX331FT799FOLZlgaNmyIQYMG4cknn8SuXbtw5MgRjBw5EjVr1sSgQYMAAJMnT8aff/6JyMhIHDp0CFu2bDEER6+++ip+/vlnnDlzBsePH8dvv/1mEjiVBqsGQGvWrMHkyZMxa9YsHD58GF27dkWfPn3yjKpTU1Ph6+uLWbNmmRSjmXPhwgVMmzYNXbt2LY2mlwi7wIiIbE/Pnj1RpUoVnDx5EsOHDzd57qOPPkLlypXRuXNnDBgwAL179zapmSmq2rVrY+3atfj111/RunVrLFmyBG+99ZbJObNnz0a7du3Qu3dv3HvvvfD398/1D/pp06bBwcEBzZo1g6+vr9nvz3bt2uGHH37A6tWr0aJFC7z66quYN2+eSQG0JXz55ZcIDg5G//790alTJyiKgtDQUEPXWmZmJiZNmoSmTZvigQceQOPGjbFo0SIAksmaOXMmWrVqhW7dusHBwQGrV6+2aPtyUazorrvuUiZMmGByrEmTJsqMGTMKfG337t2V559/3uxzGRkZSpcuXZRly5YpY8aMUQYNGlSkdt26dUsBoNy6datIryuMtLQ05WLXrooCKMpHH1n8+rYqLS1N2bBhg5KWlmbtppQp3jfv2x4Y33dKSopy4sQJJSUlxdrNKlWZmZlKXFyckpmZae2mlClbuO/8/saK8v1ttRqgtLQ0HDx4MNe8ByEhISWu/p43bx58fX3xxBNP5NulpkpNTTVU/gPStwsA6enphvkLLCU9Pd3QBZYZF4csC1/fVqm/R0v/Pm0d75v3bQ+M7zszMxOKoiArK6vQBbTlkZLd/aXeq72whfvOysqCoihIT0/PVcNUlP/2rBYAxcbGIjMzE35+fibH/fz8cvVxFsXu3buxfPnyfBecy2n+/PmYO3duruObNm2Ce1GGERRSs+xrRh45guPZs2Dai7CwMGs3wSp43/bFnu/b0dER/v7+SEpKKvYIqfIk0U7XdbTmfaelpSElJQU7duxARkaGyXPJycmFvo7VR4GZG5qX81hhJSYmYuTIkVi6dGmRZpCcOXMmpk6danickJCAwMBAhISEwNvCExWmp6fjwo8/AgDqVa2KOn37ak9evQrdqVNQunWz6HvagvT0dISFhaFXr165hlpWZLxv3rc9ML7vzMxMXLx4EZ6ennB1dbV200qNoihITEyEl5dXsb+zyiNbuO87d+7Azc0N3bp1y/U3llCE2lqrBUDVqlWDg4NDrmxPTExMrqxQYZ09exbnz5/HgAEDDMfUFJ2joyNOnjyJ+vXr53qdi4sLXFxcch13cnIqlf+JqRMh6pOSoDe+/rhxwObNwK5dQI5JqyqK0vqd2jret32x5/vW6/XQ6XTQ6/XQ660+0LjUqN8t6r3aC1u4b/VvzNx/Z0X5785qn5qzszOCg4NzpYrDwsIMcwgUVZMmTXD06FGEh4cbfgYOHIgePXogPDzc7Bop1mB2FFhaGqDWK+WYC4KIqLxRSjBEnCg/lvrbsmoX2NSpUzFq1Ci0b98enTp1whdffIGoqChMmDABgHRNXb58GV9//bXhNWptT1JSEq5fv47w8HA4OzujWbNmcHV1RYsWLUzew8fHBwByHbcmswHQsWOAWoidPW04EVF5oxalpqWlwU2d9JXIgtTaspJO4mjVAGjo0KG4ceMG5s2bh+joaLRo0QKhoaGoU6cOAJn4MOecBm3btjXsHzx4EKtWrUKdOnVw/vz5smx6iZhdC+zAAW2fARARlVOOjo5wd3fH9evXDV1iFVFWVhbS0tJw586dCnuP5lj7vrOysnD9+nW4u7vD0bFkIYzVi6AnTpxoWH02p5yzYgJFT32Zu4a1mc0A/fOPth8RASiKzCFPRFSO6HQ6BAQEIDIyEhcuXLB2c0qNoihISUmBm5ub3RVBW/u+9Xo9ateuXeL3t3oAZI/MBkDGGaC4OCAmBihmMTgRkTU5OzujYcOGFXoYfHp6Onbs2IFu3brZVcG7Ldy3s7OzRbJPDICswKQLTFGAlBSpAQIAb285fuIEAyAiKrf0en2FHgbv4OCAjIwMuLq62lUAVJHu2346Lm1Ihro0clYWkJwMhIcDmZkS8Khrl7EOiIiIqNQwALKCTGdnKGr1+q1bWv1Phw6AuvotAyAiIqJSwwDIGnQ66eoCpLtLrf9hAERERFQmWANkLd7eUuxsHAC1bw9Uriz7DICIiIhKDQMga/Hyku2mTcDJk7LfoQOgFpVduSLdY5UqWad9REREFRi7wKxEUbvAZs+WbZ06gK8v4OMD+PvLsf/+s0rbiIiIKjoGQFaSNXIkUKsW0Lw5cN99wEcfaU+yDoiIiKhUsQvMSpTx44Gnnzb/ZNOmwNatDICIiIhKCTNAtkjNAJ04Yd12EBERVVAMgGxRcLBsd+zQVognIiIii2EAZIs6dgQCAmSI/ObN1m4NERFRhcMAyBbp9cBDD8n+Tz9Zty1EREQVEAMgW/Xww7L9+WcgPd26bSEiIqpgGADZqnvuAapXl9mit261dmuIiIgqFAZAtsrBAXjwQdlnNxgREZFFMQAqQ9evAzNm6PHbb/Wwfr2u4Ime1W6wDRuAjIzSbh4REZHdYABUhs6cAT780AHLlrXE0KGOaNoU2LIlnxfcey9QtapETu+9V1bNJCIiqvAYAJWhqlWB55/PROfOl1G/vgIAWLYsnxc4OgLz5sn+yy8D33xT+o0kIiKyAwyAylCjRsB772XhxRf/wTffZAKQ3q3ExHxeNHEi8MILsj9uHOcFIiIisgAGQFYSHKygUSMgJQVYv76Ak999F3jsMakDeuQR6UsjIiKiYmMAZCU6HTBypOx/+61sFQVISjJzsl4PrFwJ3H03EB8PDB6cx4lERERUGAyArGjECNn+9ZdM9dOmDeDvDxw8aOZkFxdg7Vo54fhxYOxYiZiIiIioyBgAWVG9ekCnTkBWFtCzJ/Dvv8Dt28DcuXm8oEYNCYKcnGS7alWZtpeIiKiiYABkZWo3GAB07ixdY7/+Chw7lscLOncGXntN9l98sehdYQsXAu+/X6y2EhERVRQMgKxs7Fjgf/8DPvgA2LFDWwP17bdle+iQLAdm4oUXJH105Qrw1lvAnTvAJ58Ab76Z/4SJu3YBkycD06cD586Vwt0QERGVD47WboC9c3cHPv9cezxzpqx8sXq19HR99ZWU+qxdCwwZkn2Sqyvw0UfAoEESOa1aBVy4IM8lJQHz5+d+I0UBZs3SHu/bJ0EUERGRHWIGyMa0aweEhACZmTLwS61zfuedHDXPAwYAvXsDaWkS/Pj6yvG33zY/rn7zZkkxqfbuLa1bICIisnkMgGzQnDky6KtBA+CHHyTh8/ffwM6dRifpdMCSJUD//sAbbwDnzwNTpshzY8YAp05p5xpnfxo2lC0DICIismMMgGxQp05S3hMRIfMejh0rx999N8eJQUFSMT1rlvSlvfMO0LWrTC394INagfR33wEHDsg5330nx44cAZKTy+iOiIiIbAsDIBtVpYosBQYAU6dKwmfjRiA8PJ/pf5ycJGUUEACcOAGMHw/88YcsoQEA06YB7dvL8xkZeUw4REREVPExACoHGjbUCqDbtpXusbZtgdhYMyf7+0sQ5OgIrFkD9OsHpKdLKunVVyWS6tRJzt23r8zugYiIyJYwAConXn0VqFxZ9tPTJRM0Z04eJ99zj4wOA2SWxX79ZL0NBwc5dvfdsmUdEBER2SkGQOVEq1bAjRtAQgLwyy9ybMkS4L//8njBs8/KvEDPPgv8+CPg7Kw9p2aA9u7lchpERGSXGACVIzod4OUlI+AHDpSh8i++KEHQo4/Ksdu3jU5++WXg448BNzfTCwUHSxfZ1atAVFSZ3wcREZG1MQAqp959V2KYX38FWrSQJM+vv8rcQQVyc5OVVwF2gxERkV1iAFRONW4MTJgg+5mZQJMmsr9ggZT9FKhzZ9lu2VIazSMiIrJpDIDKsbfflp9t22SaHx8f4MwZ4LffCvHiAQNku3atzCZNRERkRxgAlWMeHsBLLwHduwOensBTT8nxDz8sxIt79AD8/ICbN4GwsFJtJxERka1hAFSBPPOM1AVt316IOQ4dHKRyGgC+/77U20ZERGRLGABVILVqAUOHyv4zzxRipYthw2S7YQOXxSAiIrvCAKiCee01qQXat08SPOnp+Zx8992yntjt24UsHCIiIqoYGABVMA0bSizj6iprh40fL8t+maXTaVmgr78u5PAxIiKi8o8BUAXUpYssB+bgIHFN//5AfHweJ6sB0MaNkg16+WUgLq6MWkpERGQdDIAqqAEDJAhycwP+/FN6uyIizJzYsqWMpffxAS5eBObPBzp2BE6dKusmExERlRkGQBXYkCHArl1SHH3yJNCunayMkaun66WXgOhomU66Th3g9GmJmLZutUq7iYiIShsDoAquXTuZJLFXL+DOHeD55yU7lGvuQ1dX4OGHgf37JfiJiwMeeSSfAiIiIqLyiwGQHfD3B/74A/j0U+kSCw0FZs3K42Q/P1kew9tblp8/dqxM20pERFQWGADZCb0emDQJWLVKHr//vtQ9m+XmBnToIPv795dJ+4iIiMoSAyA7M3gw8Nxzsj96NHDpUh4nduwoWwZARERUATEAskPvviu1QTdvyih4s2U+DICIiKgCYwBkh1xcgDVrAC8vGSU2Z46Zk9QAKCICSEgoy+YRERGVOgZAdqpBA2DpUtl/6y0zC8L7+cmQeEWRYWREREQVCAMgOzZ0KPDUUxLjjBwpUwGZYDcYERFVUAyA7NxHH8lk0DExEgRlZho9yQCIiIgqKKsHQIsWLULdunXh6uqK4OBg7Ny5M89zo6OjMXz4cDRu3Bh6vR6TJ0/Odc7SpUvRtWtXVK5cGZUrV8b999+Pv//+uxTvoHxzc5MlM9zdZfqft94yetI4AFIUq7SPiIioNFg1AFqzZg0mT56MWbNm4fDhw+jatSv69OmDqKgos+enpqbC19cXs2bNQuvWrc2es23bNgwbNgxbt27F3r17Ubt2bYSEhODy5culeSvlWpMmwOLFsj9nDrBnT/YT7doBjo7AtWtAHp8JERFReeRozTf/8MMP8cQTT2D8+PEAgAULFuDPP//E4sWLMX/+/FznBwUFYeHChQCAFStWmL3md999Z/J46dKl+Omnn/DXX39h9OjRZl+TmpqK1NRUw+OE7FFP6enpSE9PL/qN5UO9nqWvW1LDhgEbNzrghx/0WLo0Cx06ZAKOjnBo1Qr6Q4eQsXs3lBo1in19W73v0sb75n3bA3u8b3u8Z8D277so7bJaAJSWloaDBw9ixowZJsdDQkKwx5CCKLnk5GSkp6ejSpUqeZ4zf/58zJ07N9fxTZs2wd3d3WJtMRaWa9iV9TVuXB1AJ/z+ewpCQzcDAFrUqIH6hw7h0sqVOOLhUeL3sMX7Lgu8b/vC+7Yf9njPgO3ed3JycqHPtVoAFBsbi8zMTPj5+Zkc9/Pzw9WrVy32PjNmzEDNmjVx//3353nOzJkzMXXqVMPjhIQEBAYGIiQkBN7e3hZrCyDRaVhYGHr16gUnJyeLXrukunYF5s9XcO2aB5o27Yu6dQGdqyvw22+oc+QIavbuDTg4FOvatnzfpYn3zfu2B/Z43/Z4z4Dt33dCEeats2oXGADodDqTx4qi5DpWXO+++y6+//57bNu2Da6urnme5+LiAhcXl1zHnZycSu0DLs1rF1eVKsBdd0kN0K5dTmjUCEDPnoCPD3QxMXA6dAjo3LlE72GL910WeN/2hfdtP+zxngHbve+itMlqRdDVqlWDg4NDrmxPTExMrqxQcbz//vt46623sGnTJrRq1arE17MXPXrIdsuW7ANOTkC/frK/YYM1mkRERGRxVguAnJ2dERwcnKsfMSwsDJ1LmGV477338Prrr+OPP/5A+/btS3Qte9Ozp2y3bjUa+T54sGzXr+dweCIiqhCs2gU2depUjBo1Cu3bt0enTp3wxRdfICoqChMmTAAgtTmXL1/G119/bXhNeHg4ACApKQnXr19HeHg4nJ2d0axZMwDS7TV79mysWrUKQUFBhgyTp6cnPD09y/YGy6FOnWStsCtXgFOngMaNAfTuDTg7A2fOyNpg2b9rIiKi8sqqAdDQoUNx48YNzJs3D9HR0WjRogVCQ0NRp04dADLxYc45gdq2bWvYP3jwIFatWoU6derg/PnzAGRixbS0NDz88MMmr3vttdcwx+yqn2TMzU3KfLZulW6wxo0hq6befz8QGgr8/DMDICIiKvesXgQ9ceJETJw40exzK1euzHVMKaALRg2EqPh69pQAaOtW4Omnsw8OHiwB0IYNwMyZVmwdERFRyVl9KQyyPWohtEkd0IABgE4H/P03wFm1iYionGMARLl06CB1QLGxUvYDAPD3B+6+W/Z/+cVqbSMiIrIEBkCUi7MzEBws+/v2GT2hjgb7+eeybhIREZFFMQAiszp1ku3evUYH1QBoyxbg1q2ybhIREZHFMAAis9TeLpMMUKNGsnR8ejrw++9WaRcREZElMAAis9QA6N9/gdu3jZ5gNxgREVUADIDIrFq1gJo1gcxM4OBBoyfUAGjjRiA11RpNIyIiKjEGQJQns91gHToAAQFAYqLRgmFERETlCwMgypPZAEivB4YMkf1ly8q8TURERJbAAIjypAZAe/fmWANVnR56wwbgwoWybhYREVGJMQCiPAUHA46OwNWrgMmSbM2by3oZWVnA4sVWax8REVFxMQCiPLm5AW3ayL5JNxgAPPusbJcuBVJSyrJZREREJcYAiPJltg4IkLXB6tQBbt4Evv++zNtFRERUEgyAKF95BkAODsDEibK/aFGZtomIiKikGABRvtQA6NAhM9P+jB0rK8QfPAhER5d104iIiIqNARDlq149oFo1IC0NCA/P8WT16kC7drK/eXNZN42IiKjYGABRvnS6fLrBACAkRLabNpVZm4iIiEqKARAVyHg+oFzUACgsTIbFExERlQMMgKhAnTrJ1mwGqFMnwMMDuHYNOHq0TNtFRERUXAyAqEAdOkhX2IULZmqdXVyAe++VfXaDERFROcEAiArk5QW0aCH7+/ebOYF1QEREVM4wAKJCKVQh9M6dQHJymbWJiIiouBgAUaHkGwA1bgwEBspEQdu3l2m7iIiIioMBEBVK586y3b0bOHUqx5M6HdCvn+z/+KN2/MQJ4JNPgMzMMmkjERFRYTEAokJp0gTo2xfIyABeeMHMCcOHy3btWuDOHQl6Bg0CnnsO+OGHMm0rERFRQRgAUaF9+CHg6Aj89hvw5585nuzSBahdG0hIkBN+/hk4c0aeCwsr87YSERHlhwEQFVrjxsCzz8r+lClAerrRk3q9lgX67jvgvfe057ZsKbM2EhERFQYDICqSV1+VtcEiIoCvvsrxpBoA/fKLVEs7O0vK6MIFIDKyzNtKRESUFwZAVCQ+PsCMGbL/2WeAohg92bKl/KhLYowaZRg+ptu2rSybSURElC8GQFRkjz8OuLrK6vC5hsWPGKHtv/AC0KMHAEC/dWuZtY+IiKggDICoyKpUAYYNk/3PPsvx5NixQNOmwDPPyLZnTwDZGSCTdBEREZH1MACiYpk4UbY//gjExBg94eenzf8DSBeYqyt0V6/C8/LlMm8nERGROQyAqFjat5dFUtPSgBUr8jnR1VWGyAOo9u+/ZdM4IiKiAjAAomKbNEm2X35ZwInZdUC+DICIiMhGMACiYuvfX7anTgGJifmc2LcvAMD/wAHg/PlSbxcREVFBGABRsVWtCvj7y/6JE/mc2LYtsu67D/rMTOjffbdM2kZERJQfBkBUIi1ayPbYsfzPy3rlFQCA/quvgKioUm4VERFR/hgAUYkUNgBSunTB9ZYtoUtPB95+u/QbRkRElA8GQFQihQ2AAODk0KGys3w5cOlS6TWKiIioAAyAqETyC4CWLQPuuQeIjZXHN1q0QFa3bjJ2/oMPyq6RREREOTAAohJp3ly2V69qgY7qrbeA3buBn3/WjmW9+KLsfPEFcONGwW/www9AUFABkw0REREVDQMgKhFPT6BuXdk3zgJdu6YtAH/6tHZc6dULaNsWSE7WZos2R1GAd94Bhg6V1eQLnGyIiIio8BgAUYmZ6wbbu1fbP3PG6GSdTltO/pNPgKQk8xd98UXtPAD491+uJUZERBbDAIhKzFwAZLxKvEkABAAPPQQ0aADcvAl8/nnuCx4/rtUIffAB4OQEJCRw+DwREVkMAyAqscJkgEySNw4OkuEBgFdeMT0ZAF5/XV4wZAgwdaqsKg8AR45YvO1ERGSfGABRiRkHQIoCZGQABw5oz9++LUXSJh5/HOjXD7hzBxgwQNbTAGRK6R9+kP1XX5Vtq1ay5VpiRERkIQyAqMQaN5akzq1bwOXLEqekpAA+PkCdOnLO2bM60xc5OgJr1siy8jduACEhMtLrtdckiho8GGjdWs5VtwyAiIjIQhyt3QAq/1xcgEaNgIgIyfxER8vxjh2BrCwZxHX2LODrm+OFHh7Ab78BnTsD584BTzyhPadmfwBmgIiIyOKYASKL6NlTtpMnAxs3yv7dd0utMwCcPq0z+zr4+UnU9M472slDh8pQeZUaAJ0+LcPniYiISogBEFnEm29K/BIVBYSGyrFOnYCGDWU/VxeYsSpVpCj65EmpAfrqK9Pn/fwkfZSVJSPEiIiISqjIAVB6ejp69OiBU2rRKhGASpWAn34CXF21Y3fdpSV18g2AVHq9jPhycTE9rtOxDoiIiCyqyAGQk5MTjh07Bp2uEF9oZFdatwYWLZL99u2BypW1ACjXUPiiyqsOaO1a4OuvS3BhIiKyR8XqAhs9ejSWL19u6bZQBfD448CePcCGDfK4Xj1J4CQl6XDrlku+r82XuQBo927gkUeAMWOkypqIiKiQijUKLC0tDcuWLUNYWBjat28PDw8Pk+c//PBDizSOyqdOnbR9Fxegdm0ZCRYd7ZH3iwqidoEdOSKppNRUGTWmppW2bwfq1y/+9YmIyK4UKwA6duwY2rVrBwC5aoHYNUY5NWhggQCoaVOZOyguDhg/HnBzk6Jp1c6dwLhxJW8sERHZhWJ1gW3dujXPny1bthTpWosWLULdunXh6uqK4OBg7Ny5M89zo6OjMXz4cDRu3Bh6vR6TJ082e97atWvRrFkzuLi4oFmzZli/fn2R2kSWpY4EK1EA5OICvPyy7K9YAXz2mew/9ZRsd+wo/rWJiMjulHgY/KVLl3D58uVivXbNmjWYPHkyZs2ahcOHD6Nr167o06cPovJY9DI1NRW+vr6YNWsWWqtdIjns3bsXQ4cOxahRo3DkyBGMGjUKjz76KPbv31+sNlLJqYXQJQqAAGDuXGDXLqBNG3k8bJjMH6TXy0SKxfw7JCIi+1OsLrCsrCy88cYb+OCDD5CUlAQA8PLywgsvvIBZs2ZBry9cXPXhhx/iiSeewPjx4wEACxYswJ9//onFixdj/vz5uc4PCgrCwoULAQArVqwwe80FCxagV69emDlzJgBg5syZ2L59OxYsWIDvv//e7GtSU1ORmppqeJyQkABAhvynp6cX6l4KS72epa9ry+rW1QFwxLlzPkhLK+F933WXLJ565IgURjs6wrF1a+gOH0bG1q1Qhg61SJstxR4/b4D3zfuu+OzxngHbv++itKtYAdCsWbOwfPlyvP322+jSpQsURcHu3bsxZ84c3LlzB2+++WaB10hLS8PBgwcxY8YMk+MhISHYs2dPcZoFQDJAU6ZMMTnWu3dvLFiwIM/XzJ8/H3Pnzs11fNOmTXB3dy92W/ITFhZWKte1RXfuOMLZuTeuXPHEokXb0ahRvGUunL3CaouaNVH/8GFcXLUK/3p5WebaFmZPn7cx3rd9scf7tsd7Bmz3vpOLsFpAsQKgr776CsuWLcPAgQMNx1q3bo2aNWti4sSJhQqAYmNjkZmZCT8/P5Pjfn5+uJpr6fDCu3r1apGvOXPmTEydOtXwOCEhAYGBgQgJCYG3t3ex22JOeno6wsLC0KtXLzg5OVn02rbsl19k7dPTpzsjj9KtYtOlpgK//YagqCjU6tvXshcvIXv9vHnfvO+Kzh7vGbD9+1Z7cAqjWAHQzZs30aRJk1zHmzRpgps3bxbpWjlHjSmKUuKRZEW9pouLC1xyzj4MmfSxtD7g0ry2LRo7NgNr1gA//uiIjz/WmcwYXWI9egAAdMePwykxUZbWsDH29nmreN/2xR7v2x7vGbDd+y5Km4pVBN26dWt8+umnuY5/+umneRYn51StWjU4ODjkyszExMTkyuAUhb+/v8WvSSXXo4eCatWSER+vw88/W/jivr6AGpDv2mXhixMRUUVUrADo3XffxYoVK9CsWTNDEXOzZs2wcuVKvPfee4W6hrOzM4KDg3P1I4aFhaFz587FaRYAoFOnTrmuuWnTphJdk0pOrwd69LgIAFi5shTeoFs32f7xRylcnIiIKppiBUDdu3fHqVOn8OCDDyI+Ph43b97EkCFDcPLkSXTt2rXQ15k6dSqWLVuGFStWICIiAlOmTEFUVBQmTJgAQGpzRo8ebfKa8PBwhIeHIykpCdevX0d4eDhOnDhheP7555/Hpk2b8M477+C///7DO++8g82bN+c5ZxCVnZ49ZXqDTZuAS5csfPFHHpHtypXA9esWvjgREVU0Ra4BSk9PR0hICD7//PNCFTvnZ+jQobhx4wbmzZuH6OhotGjRAqGhoahTpw4Amfgw55xAbdu2NewfPHgQq1atQp06dXD+/HkAQOfOnbF69Wq88sormD17NurXr481a9agY8eOJWorlVxAQDK6dcvCjh16fPQR8MEHFrz4ffcBwcHAwYPAxx8Dr79uwYsTEVFFY/XV4CdOnIjz588jNTUVBw8eRDe1KwPAypUrsW3bNpPzFUXJ9aMGP6qHH34Y//33H9LS0hAREYEhQ4ZYpK1UctOnZwEAliyxcKJGpwOy537Cp58CRRgJQERE9oerwVOZCglR0L49kJwMWHzN3AcfBBo3BuLjgS++sPDFiYioIuFq8FSmdDrg1VeBgQMlUTNtGlC1qoUurtcDL74oq8R/+CHw3HOAs7OFLk5ERBVJsTJA6mrw3t7eOHXqFA4fPmz4CQ8Pt3ATqaLp31+W80pKAubMARTFghcfORIICACiowEugktERHkocgYoMzMTc+bMQcuWLVHFBiecI9un00ngM3iwZIFu3gSWLgVOnwb++Qfo3RuoVauYF3d2BsaPlyLoJUsAG1sbjIiIbEORM0AODg7o3bs3bt26VRrtITsxaJAEP46OwKpVQOXKkhUaPx4YM8b03PBwqRkyZ8UKWRDexJNPSnfYtm3Af/9ZvvFERFTuFasLrGXLljh37pyl20J2ZtIkICwMqFYNSEsD1HVnt2wB1NkPvvoKaNsWePnl3K9PSwOeegqYMQO4fNnoicBA6WcDJAtERESUQ7ECoDfffBPTpk3Db7/9hujoaCQkJJj8EBXWvfcCx48Du3dLV1j37nL8+++lNkjN7mzfnvu1UVFARobsX7mS48mnn5btV1/lnT4iIiK7VaxRYA888AAAYODAgSbzAamLjmZmZlqmdWQXqleXH0BqmLdvB775RjI/ERFy/L//gMxMwMFBe11kpLYfE5PjoiEhQN26clK9evIGffqY6S8jIiJ7VKwAaOvWrZZuBxEA4OGHpWvs+HHAePWSO3eAc+eAhg21Y8YB0LVrOS6k1wPTpwMTJ8qT164BR48CQ4YAhZkV/PhxYPVq6XtzcyvJLRERkQ0q9lpger0eS5cuxYwZM9CgQQN0794dUVFRcDD+JzpREfn4AAMGyL6a/QkIkK3Rkm8ACsgAAdINdumSLI+hzga+cGHhGjJtGvDGG6whIiKqoIoVAK1duxa9e/eGm5sbDh8+jNTUVABAYmIi3nrrLYs2kOzPyJHaft++sswXIEkZY/lmgFQ1awLt2gGzZ8vjH38seCVWRZHx+ACwc2eh201EROVHsQKgN954A0uWLMHSpUvh5ORkON65c2ccOnTIYo0j+9SnjzY79PPPA82by36xAiBVmzZScZ2RAXz2Wf7nXr4MxMbK/q5dFp6pkYiIbEGxAqCTJ0+aLFqq8vb2Rnx8fEnbRHbOxQX4/XdgzRqpZS5MAGS2Cywntajo88+B27fzPu/wYW3/+nXgzJnCNJuIiMqRYgVAAQEBOGPmS2HXrl2oV69eiRtF1KED8Oijsq8GQOpIMECW0TBeTb7ADBAgcwPVrw/ExcksjHkxDoAAyQIREVGFUqwA6KmnnsLzzz+P/fv3Q6fT4cqVK/juu+8wbdo0TJw40dJtJDsXFCQDsVJTZSQYAJw/b3pOoTJADg7ajIqvvipTTJujBkA+PrLdvbtI7SUiIttXrADoxRdfxODBg9GjRw8kJSWhW7duGD9+PJ566ik888wzlm4j2Tm9HmjaVPbVbjC1+6tGDdnGxmrZoXw9/risw5GWBgwbZn6SRDUAGjdOtswAERFVOMUKgACZDTo2NhZ///039u3bh+vXr+P111+3ZNuIDHLWAakBUIcOsrhqVpZWt5wvnQ5Ytkwip//+A+66Sy5y990yzv7mTeDCBTlXzWaePGna30ZEROVesQMgAHB3d0f79u1x1113wdPT01JtIsolrwCoQQNtxFihusEAWXzs668lGDp+XIa8798PvPSS1i0WFCT1Qs2ayeM9eyxwF0REZCtKFAARlZW8AqC6dQE/P9kvVCG06r77ZI6fb76RH70e+O03YOVKeb5tW9l26SJb1gEREVUoDICoXFATMSdPylQ+5gKgQmeAVF26yKyLI0dqQ86++Ua2agB0zz2y3bGj2G0nIiLbwwCIyoWgIMDTU0aC/fGHaQCkLqRapAxQTuroMJUaAPXoIV1l+/dzPiAiogqEARCVC3o9MGGC7D/1FJCYKPtBQcXsAsupZUtg4EDtsRoABQYCvXvL/hdflOANiIjIljAAonLjtdckHrlyRR77+8v8QGoGqMhdYDm98opEWvXqaePrAS3y+vJLSUEREVG5xwCIyg1PT+Djj7XHdevK1iIZIECGw+/ZA2zaJN1eqn79ZFHV2Fhg3boSvgkREdkCBkBUrgwaJCtaAECjRrItdhG0OR07yvB3Y46OwPjxsr9kiQXehIiIrI0BEJUrOh2wYgUwcyYwa5Ycs0gRdEHGj5fusR07cq/KSkRE5Q4DICp3fH2Bt94CGjaUx8ZdYIpSSm9aq5aknwBg9uxSehMiIiorDICo3FMzQGlpQEJCKb7R669LFmj9es4LRERUzjEAonLPzQ3w8pL9Uu0Ga94cePJJ2Z86VRYgIyKicokBEFUIFi2Ezs/cuRJtHTwIrFpVym9GRESlhQEQVQjGhdCbNwNbtpTSG/n5SQU2AEyZAly8WEpvREREpYkBEFUIagbo5ZeBXr2ABx4oxWzQlCkyU3RsLPDQQ8CdO6X0RkREVFoYAFGFoAZAp07JNj1d1gwrFa6uwNq1QJUqwIEDwHPPldIbERFRaWEARBWCOnehnx8wYIDsb9xYim9Yty7w/fcyMdHSpcCkSRJ1ERFRucAAiCqEp58Gvv0W+PdfbWH3P/8s5ZgkJARYuFCCoEWLpN/t5k3t+YgIOPTsidphYaXYCCIiKg4GQFQheHgAI0ZIMXSHDkC1asCtW8Du3aX8xs8+K/MCeXpK5XXnzsCFC1KN3bcv9Lt2oeXy5aaBERERWR0DIKpwHByAPn1kv1S7wVSDBskiqrVrAydPAl26yAKq588DABzv3IH+s8/KoCFERFRYDICoQurXT7ZlEgABQMuWkm5q1gy4fFnmCapcGZlz5wIA9J9+WsrTVBMRUVEwAKIKqXdvyQRFRADTpwNNmwKDB5fiWmGArBe2cydw772Ajw+wfj2yXnwRiTVrQhcXByxeXIpvTkRERcEAiCokHx/gnntk//33gf/+A37+GTh0qJTfuEoVYOtWqQHq3h1wcMCphx+W5z74AEhOLuUGEBFRYTAAogpr0iTAyUkSMsHBcmzDhjJ6c2dnw+7lbt2gBAUB168DP/5YRg0gIqL8MACiCuuRR2SF+K1bgcmT5dj69WXfDsXBAVnjxsmDFSvKvgFERJQLAyCyC/36AY6OwPHjwOnTZf/+WSNHAno9sGNH7gYoCvDPP0BKStk3jIjITjEAIrtQuTLQo4fsWyMLhFq1pDIbAFauNH3uk09k8qKXXirzZhER2SsGQGQ3Bg+WbVECIEWR+GTrVgs04PHHZfvVV0BmpuzHxwNz5sj+zz+X8jA1IiJSMQAiuzFokGz37QOiowv3mm3bZK3TsWMt0ICBA2WU2OXLgLo8xrvvAnFxsh8VZZg8kYiIShcDILIbNWsCHTvK/rJl5s/JmYBRMz9RURYYwe7iAowcKftPPimZoAUL5HGlSqZvSEREpYoBENmVp56S7dy5uWON2FigTh1tFmkA2L5d24+MtEADpk0D6tUDLl2StFJKiqwfNmmSPL9tmwXexIx//gH+9z/gxo3SuT4RUTnDAIjsytixwKhRUoLz6KPAxYvac0uXyuPQUFnS684dYP9+7flz5yzQgMBAWbL+hRdkVJhOB7z9tlahvXWr5euAUlKAhx6SG/z2W8tem4ionGIARHZFpwM+/xxo21YyPg8/DGRkSEC0ZIl23k8/Sa1Qaqp27OxZCzXCw0Ompz52DNi7F+jaVbJATk6SGbJIpGVk4ULpwwPk+kRExACI7I+bG7BunSyX8fffEh+EhmoxAiATNht3fwEWDIBUTZtqRUnu7tp+SeuA/vhDhtUvWyZLcrz1lvZcYau/iYgqOAZAZJeCgiQJAwCvvgrMmyf748bJIqpHjgDffCPH2rWTraUTM7mo3WAlrQP64gup+XnySaB5cyAxUWaBBICrV0t2bUs6dQp48EFpKxFRGWMARHZr3DhZJyw5Wb6DdTrg5ZeB++6T59WMj7qKhcUzQDnde69sw8Jk5fhly4BnnwXuvlsKljIyCnediAjZ6nRa0fPLL8vWljJAX38ti7N98YW1W0JEdsjR2g0gsha1HqhVK6n1eeABoH59qQvatEnOqV4d6NtX9iMjpVbIwaGUGtSpE+DqCsTEABMnmj63f78MTxszJv9rpKcDZ87I/vbtsvZY48ZA//6S5rKlDNC1a7K9ft267SAiu8QAiOxao0YyFc/cucDs2XLswQeBp5+WYKdbNxm45egoC6teuSKPS4WbG7BqlcwInZgoqakmTYBbt4AvvwTeeAMYMULrzjLnzBnJFHl6AvfcIwXWgJYJunlToj0Xl1K6iSKIiZEth+YTkRVYvQts0aJFqFu3LlxdXREcHIydO3fme/727dsRHBwMV1dX1KtXD0uMh+5kW7BgARo3bgw3NzcEBgZiypQpuHPnTmndApVzEyZIz1CnTvK4WjWtG+z++yXeCAqSx6XeDfbgg7JW2Nq1wO+/Ax99BHz8sTTqzBng++/lPEXRltMwpnZ/NWkiKS5VlSoyygywnSwQAyAisiKrBkBr1qzB5MmTMWvWLBw+fBhdu3ZFnz59EGU8HMdIZGQk+vbti65du+Lw4cN4+eWX8dxzz2Ht2rWGc7777jvMmDEDr732GiIiIrB8+XKsWbMGM2fOLKvbogpgxQqZNueJJ+Rx/fqyLfVCaHM8PWXeIECyQK+/LgFN27bS5WVMDYCaNjU9rtMB/v6ybysBkNr1xQCoYsr5t0lkY6waAH344Yd44oknMH78eDRt2hQLFixAYGAgFi9ebPb8JUuWoHbt2liwYAGaNm2K8ePHY9y4cXhfHc4DYO/evejSpQuGDx+OoKAghISEYNiwYfiHI02oCGrWBMaP13qb6tWTbalngPIyaZIEPadOybC1+Hjg6NHcI8byCoAAICBAtrZSCG2cAeIisBXLd98BXl7Ar79auyVEebJaDVBaWhoOHjyIGTNmmBwPCQnBnj17zL5m7969CAkJMTnWu3dvLF++HOnp6XBycsI999yDb7/9Fn///TfuuusunDt3DqGhoRiTT/FoamoqUo1mvEtISAAApKenI93C/4pRr2fp69q68n7fQUF6AA44fToL6elmup7yYLH7dnWF/pVX4DB1KpRmzaBUqQL9rl3IXLsWWeroMQCOJ05AByCjYUMoOd7Twc8PegCZly8jq5Q/hwLv+84dOCUmyn5GBtJv3NDWQyvHyvvfeXHlvG+HrVuhT01F5vbtyHrgAWs2rdTws7bN+y5Ku6wWAMXGxiIzMxN+fn4mx/38/HA1jxT91atXzZ6fkZGB2NhYBAQE4LHHHsP169dxzz33QFEUZGRk4Omnn84VaBmbP38+5s6dm+v4pk2b4O7uXoy7K1iYuhq4nSmv9x0X5w+gI8LDbyE0dEeRX2+R+65XD67LluFOlSqofvgwOu3ahfQffsCfvXvLshpZWeh34gQcAWyPiUFSaKjJy1ulpaEugNM7d+JkrVolb08h5HXfrtevo7fR421r1yJZ7aKrAMrr33lJqffd7vRpBAK4EBGBozn+Disae/+sbU1yEVattvooMJ1xoSYARVFyHSvofOPj27Ztw5tvvolFixahY8eOOHPmDJ5//nkEBARgtjrMJ4eZM2di6tSphscJCQkIDAxESEgIvL29i3VfeUlPT0dYWBh69eoFJ7Uo1Q6U9/uuVUuW7LpxwwctW/bFM884oFcvBc88k5Xv60rtvnv1grJgAVzj4tCvWjUod98NREXBMTUVipMTuj3+eK7RYvqDB4E//0QjT0/UV8f2lxL1vu+9txcyM53g5ZXjhEOHTB72aNUKSvv2pdqmslDe/86LK+d9OyxfDgAIqlYNgaX8t2Yt/Kxt877VHpzCsFoAVK1aNTg4OOTK9sTExOTK8qj8/f3Nnu/o6IiqVasCAGbPno1Ro0Zh/PjxAICWLVvi9u3b+N///odZs2ZBr89d9uTi4gIXM8OCnZycSu0DLs1r27Lyet+NG8v25k0d7rvPCefPy4oVo0c7IPtPL18Wv28nJ5nb5/vv4fjrrzLcPXv+H13DhnByc8v9mpo1AQD6mBjoLdWWzExZV6RLF6BGjVxP9+/vimPH9Dh/OA6VvnhP5jFq3BiIizM5z/HWLW2UWgVQXv/OS8pw39n/CtcnJ1vub81G2f1nbWOK0iarFUE7OzsjODg4VxotLCwMnTt3NvuaTp065Tp/06ZNaN++veGmk5OTcwU5Dg4OUBTFkC0iKipPT0CNy8+fl+2dOzI9j9U8+KBs162TImLjIfDmlEYR9G+/ySzVzz9v9umDB3WIjwfOLPgNmD9fRrEBWgG0iiPBKpbbt023RDbIqqPApk6dimXLlmHFihWIiIjAlClTEBUVhQkTJgCQrqnRo0cbzp8wYQIuXLiAqVOnIiIiAitWrMDy5csxbdo0wzkDBgzA4sWLsXr1akRGRiIsLAyzZ8/GwIED4VBqU/iSPVCHwtepo02auHgxkJV/L1jp6dNHJjQ8e1ZWls9vBBigBUAFDYMvyg39959sT57M9VRmJpCSIl3T8aezh7yfPi1bBkAVmxr4JCVZtx1E+bBqDdDQoUNx48YNzJs3D9HR0WjRogVCQ0NRp04dAEB0dLTJnEB169ZFaGgopkyZgs8++ww1atTAxx9/jIceeshwziuvvAKdTodXXnkFly9fhq+vLwYMGIA333yzzO+PKpZZs2T5qvnzJRv08ccyL9Cff0osUuY8PYGQEBlq/NRT2pdOXgGQ8TxAWVlSOG1s2zbglVeAf/8F9u0DmjUruA0XL8r2ypVcT6Wlaf97ibuY/UUYGSnbnMtfMACqWNTAhxkgsmFWL4KeOHEiJuZc9yjbypUrcx3r3r07DuUooDTm6OiI1157Da+99pqlmkgEQNYEM67nfPxxWUZj0SIrBUCABCw7dgB792rH8gqA1D68jAwJOHx95XFamnRj/fyzdm5YWOECoEuXZHvjhvQJuroC0dFwmDQJbg26AugHAIi/mj0Te0yMfCmqGSBnZ3n/EgRACxcCdesCAwcW+xJkacwAUTlg9aUwiMorNW7fuNFKM0QDwF13yVL2LVrIY51Oq9jOydlZltQATLvBNmyQ4MfJSXut2p1WEDUAArTaotWroV+/Hn6/bjU8FXfDqFvt/HktAGrUSLaxsYV7P5WiANev49w5YPJk4H//K9rLqZSxBojKAQZARMXUsKGsIK8ospiq1TRoIF1WL7wAfPAB4OGR97lqN5hxIfRvv8n2ueckowQUPgBSu8AA4PJl2WZXiSvRiYan4rOMxsFHRmpdYGrBdlEzQG+/DVSvjpsbZE6mHIPKyJqyshgAUbnAAIioBObNk+0330jpjNV4eADvvw9MmZL/eTkLoTMzAXWiugEDtO6zEycKfs/UVNNiZrUO6MIFufQtbUbWOFTWzjt3Tnud+n5FDYB27wYA3D4iQ//T0qRnj2xASoq2zy4wsmEMgIhKoEMHKZ9RFODll63dmkLImQHat0+CDx8fmctHzcjExubullIUWan+1Cl5rGZ8VDkCoCR4Gp6Kh492nnEGqLgBUPZ7JcVos74WYQJYKk3GQU9GhkSnRDaIARBRCb3xhky6vHEjsH27tVtTgJxzAandX336yE14eMg4fyB3N9h330nlt1pwY1z/A2gBkZkAKA6VtYkOjx3TopUSBkC3b9wxHGJvi43I+UEwC0Q2igEQUQk1bAg8+aTsjx4t3+82K2cXmBoA9e+vnZNXN9i338r24EHJBuUMgK5cARITDQU5uTJAd98tDw4ckK2rKxAUJPu3b0uXWmGkpxu60G7HadmFipIBKvfzteYMgBiZko1iAERkAXPnSi1yVBTQqRPw2WcyWeKgQQ744INgzJmjx5Yt1m4lTLvAzp+XaM3BQaq5Verwd+MM0PXrwObNsp+UJDeqFkC7usr2yhVD9gcwkwHq2VMe3LolW19fWQFenaC0sFmgq1cNUcLtW1rhT0X4nk1PB9q2BR55xNotKYGcGR9mgMhGMQAisgBfXymnufde+f/9M89I19jvv+uxc2ctvPWWA+67D1i1ysoNVTNABw8Cw4fLfpcuQJUq2jlqBsg4APrpJymYVh07pmWAgoNle/myIQBSdLrcGaAePUzbUr26DNtX37uwAZDRpIu3E7U2VYQMUGQkcOSIzExQbjEDROUEAyAiC6laVWaFnjZN/hU/Zgzw8ceZGDPmOPr1k3lwnn5amwzZKlq0ALy95UtJnTzRuPsLMB8Aff+9bI3reNQMUMeOsjXKACkdOuA2tOH48fCR66oBGKBNxFi1Kg6jDf7eVchiWeMA6I62vE1F+J5VkyUZGZINKpcYAFE5YfWZoIkqEmdn4L33tMfp6VkIDT2DkJBG6NVLj927gZEjpVja0Rr/9VWtKhHY3r1Si5OQIFGZMTUAunhRanpu3QJ27pRjTzwBLFlimgG66y7Z3r4NHD0KAFDuugu3DlUGsnuoUuGKFE8XuNWtqxVgV68OAMioUh098DPSp3ji+hjA3b2AezAOgIyCrIqQAUrUpk5CSooWb5Yr7AKjcoIZIKIy4OgoNcTe3sCePdr8QVZRpQrQrx8wZw7w4YeypljO59VlM/77D1izRvbvuUdb88M4AGrcWGp5AC2rVLs24j2qm1w2/pZO1qxQZQdA8V6BuAUfJKc65loj1aw8AqCKkGgwjhXKbUDHDBCVEwyAiMpIUJAkTwDg9deBX36xanPyp2aB/vhDgiQAGDZMW3LjxAng2jXZr1ULqFlT9tUMUO3aiHf1NblkXBxMA6DsLrB4z1qm5xSkAmeAjAMg4/kEy4vERCDpZo6uTGaAyEYxACIqQ8OGAc8+K/sjR0qCxSapAdCrr0rA0bSpNDgoSPqo1MntXF2lW61GDXmcJbVOSlAQEpwqm1wyPh7mM0BuWl1QqQVAGRmyeJvVq9DzV54zQJmZOrRu7YiW74xApvFXCzNAZKMYABGVsQ8+ALp3l38td+4MtGolZTTqlDzF9dlnwNdfW6aNJivB16kjq8N7ewN6PdC8ufZcrVoykksNgFS1ayPRwdvkUK4MkBoAuVQ3Pacg6oSL1asXvgts505g8WKZqGn//kK8iXWU5wAoIcEZly7pcD6+sskIQGaAyFYxACIqY05OwA8/SDIlLk56jQ4cAMaOLfqi6KrISBl6P3as1jNVImphs5+fzP+jdnEBWjcYAAQGytb4eXd3oGpVJOlMa4tyZYCyu8DiHIsYAKkZoDZtTDNAscmyqr25RcHUwuvMTGDUKNvLSqSmAnv2IPFWluFQeesCS07WKraNPxeb+10TZWMARGQF1asDx48DW7dKcqVVK5kGZ9q04l3v8GHZKoq2tmmJ3HUXsGWLXLhBA9PnjAOgWtn1O8YZoDp1AJ0OyRkyQWJVSFQXF5d9vjpxYvZr4vXaHEQFBkApKdpJOQKg26HbgcGDgR9/zP0646jw9GngxRfzfg9rjD9/802gSxck7T1qOFTeMkDJydqwxmS4S7YQYABENosBEJGVuLvLxIn33w98/rn0JH31lQRFxs6ckZFj+a12fuSItv/rrxZqYI8epvP2qMwFQMYZoOy1xO7ckS/EQH9peHw8AEdHPNfzKAa3PoesAHlNvFLJ8NICAyA1k+PqCjRqZJoBis6eYdpcYZU6vKxdO9kuWiSTQeb0339A5crAjBkFNMTCjh8HACRdvmU4VP4CoBwZoOwuTnaBka1iAERkA+6+W5uO53//07rC/v4baN1aJmuuXl16b6Kicr/eOADatAm4cyf3ORZjrgssZwYIWgBUq70svxEXJ1/qn4Q2wM9H6uLsWTk9PtPL8NICAyC1+6tmTcDPzzQDFJ9ueo4xNQP00EPaUH5ztUDbt0vGoqQFWUWVHaAl3dJmti5/XWBaBug2PLSpFJgBIhvFAIjIRrz1lsQRZ85IkfTOnTJJc3KyzCMUFydzCc2dm/u1agCk08n3TamuSh8QIFkSIO8uMAB3smdpVmOk+Hi5N5W68kV8ujbzYdwNrQbGLDW4qVEjVxF0spLdtaYWSRtTM0DVq2sj3NQIzJgaXV64ULarkma3z3gixPKcAUqGOzNAZPMYABHZiEqVpB6oRg2ZZqdbN1mDtG1b2a5YIeeFhpp+N9+6JeuaAsDDD8vWYt1g5uh0wPjxUhvUubMc8/eX4wBQpw7S0oCMDAmA1BgpPl7Kb1Rqlisuxc1wLG7zQW2lenOMAiDFt7rJaCNDMJRfAOTnB9SvL/vG0ZhKXd4jKamQFdkWomaAkrX/JZe3AOj2bWaAqHxhAERkQ5o1A3bt0r6j69QBNm4EfHxk7VIPD4kPwsO11/z7r2wDA6WLDJAAqFQTGO++K9FM1ary2MlJW2m+bl2T7zy1PCguznwAFJ+g/W8oLk6RiO+oVgxswigASqvki0zkKLw1PseY2gVWvbpW1G0uADLuXzRa2b7EFEXmIZo0KfcHk5aWXSAFJKVqWZTy1gWWkpLjs1ADIGaAyEYxACKyMXXrArt3y5pi27drdcguLlIwDZiO9FK7v1q3Bu67T+qDo6LyjiFKzQcfAJMnAx07Gr7znJ0VQ09Izi4wQwAUrx2Lc/aTCG/WLPPvoWZ3atQwHWoNowxQbKwMK1cpimkXmBoAnTtnmLjRoLQCoNOnZR6iRYtyz1Nw/bphN6kcz2x9+3aOImhmgMjGMQAiskF+fjIkPrucxqBvX9nmFQC5u2tB0k8/lX47TQwbBnz0EaDXGwIgT0+tXCjPDFC8dizOPTtdtHGj+a4sowxQzu9VQwbI+DxACmvUqvDq1YHataWo6s4d0/OysrT1zQDLBkDGRVk578toAbREaAXh5S0AyjMDxACIbBQDIKJyRB3AtG+fVkRsHAAB0lUGSM1QfkPnS9Pt21IP5Okp3XdA7hogNfFhHADFJzpCuaerBCNq0ZOxggIgFxfT8wAtwPDwkB9HR5mFEjAthL52zXQOIEsGQDt2aPs5AyCjjJBxTVN56wLLlQFiETTZOAZAROVIYCDQsqXEB5s2ycTGx47Jc2oANGSIlOZcvmyhSRGLQQ1O3N21DFB8vDaND2A+A5SZCSSOniQPli/P3UWVTwB0Gx7aPD/GQYZxAbTKXCF0zvkFLBUAKYppBsg4y2TcPpgGQOU5A8QuMCoPGAARlTPG3WCnT0umwN1d+053cZElMQDgiy+s0kSjLjDFkAHKSS3VyZnpiOs2SNJGFy7IsDjVrVvahQMCDN+rTpCFWZP1ntqYe+MAyLgAWmWuELq0AqALF7TRZUCeAVAm9Egx6sYrbwFQrmHwagCUkiKRLZGNYQBEVM6oAdC6dbL+FyBZIQcH7Zz//U+2v/9ufuLE0mZcA+TiArhpI90N7YyN1bI/Op0Wn8SluGrD2YwjuC+/lG1QEODlZQiAfCF9aclZrlBqZNcQmesCM84AqQGQcReYGqSo8wRZKgDKOSlTHjVASTrTxWPLdReYzktL/QHlL5oju8AAiKic6dRJvqOTk4G//pJjaveXqlEjWckiKwtYtqxk7/fRR0DHjkVbqFUNTjyyBzUZZ4HUthoHQN7e2oj6uDhoEdyGDTIjZFKSzBQJAC+/bPIeagCkQI87ftlV4+a6wIwzQPl1gXXtqjXQEt03av2Pmp3KIwOU1KCNyeHyFjOYFEE7estwRHVuKNYBkQ1iAERUzjg5yRqlGzdKV1dwsBYvGHvqKdkuWyZTzRTXRx/JkhwbNhT+NUlJWhE0YJoM6NRJtnFxWlDl42M6WgwtWgCjR0sEN2wY8NprUjVdv76hfy9nAAQAtytnz7pYlC4wdV4eNQBq2VIiMsAyWSA1AzRsWO62AVoA1KS9yeHyFgCZZIAcvCX4Uf8AWAdENogBEFE55OIiXWFffgn8848EQTk9+KDMIRQdDaxZU7z3iYvTeobUFecLI78MUMeOslUUIDJS9itXzhEAAcBnnwFNmkjA8OGHcmzuXIkAjd7DGwlwgQxzT66SHQAZdYEp18x0gdWtK1/QiYlaFKbeaO3a2vwDJQ2ALl+Wbja9Hnj0UTl26ZLpZIhqAFS/lclLy1MXWGamtvYbANzWZw/nV/8AmAEiG8QAiKiCcnYGnntO9t97r3gzQxtPpnjoUOFfZ1wEDZhmgJo21R6rw+JzZYDkxcAPP0hXCgA0bw489pjhOoYgC7fhDkmX3PbOnjXy8mVAUfD220Cl9V9iGt7DDbdaWiNcXbU1OtRuMDUDZMkASO3+attWqy26fRtISNDOUdcBC2xu8tLylAEyXsMMAJJ12YEPM0BkwxgAEVVgTz0l/wg/etR0QFVhqctsADLfUH6DeRRFC7LyywA1aABUqyb7auxhNgACpDvqyy+l6+vTT00qvQ3vUc8fHt5yPNkzu5srJQWIj8fGjUBipgc+wDTUmzwAX39tdG21DujsWZkUUa0VCgy0XAD0zz+y7dzZdE4AtQ5IUQxddEk+EpDpkWm4hfLCOJ4DjGblVv8AGACRDWIARFSBVa4s65YCkgXasweYMaPw9TzqJIuAfCGfPJn3uY88IkmVmzfzrgGqVk2CnUIHQIBkfc6cAe691+SwIQB6MATu/pXkWKardqErVwy9WwG4goTbjnj9daMLGNcBqQGJuztQpYrlAqBTp2SrZn/UrJP6fgkJhgKtJEcfAEaj2spRBujWLdPHycge9qf+AbALjGwQAyCiCm7yZClB2bwZ6NIFeOcdiSnUSQnT0oBXXpFh9TmpGSB1ME9e3WDHjwNr10rpzd69psPgAS0D1LChbHMGQGZrgApgnGVSEw3JydBWX718GbGxkpL6DDK5oslC88YBkHH3l05nuQBI7eNTb9yobQC0rJOXF5LSnAEA1RGj3Us5kZCgM3l8Oys7AGIGiGwYAyCiCi4oCBg5UvY9PaUwOjVV1i4FpL74zTclKFJnlQZMZ5lW1xfLqxBanaIHkCyRFpwohjYAQJs2slUDoJs3ZZtvBigPxgGQe/b8gcnJAGrUkPZfvGK4fnP9fwAkMDN8F6sB0O7dWmqrdm2YNLgkAVBGhiy4CmgBUM4MkNEQfTVoVAOglJTi1W1Zg9oF5uYkS4nczsyu22IRNNkwBkBEdmDJEplO59o1bV6gJUuki+uNN+RxerqMMFfXDzt3TgIKNzdtAJOaATp7VobhK4q8zri25tSp3DVAI0fKSDS1C0oNgFTFCYCMs0wmiYbsLEv8uZvIypLMRF3fJMNkjIalt3r1kmDp/Hlg9mw5ps7Vo2aArlwp/hwCFy/KL8fFRbuuGgDlzABVr24oJFYDIAC4c7N8pIHULrAanhIJJWdmr8nGImiyYQyAiOyAmxtwzz2SKenTRwYl3b4tZTW3b8sw+sqVgYMHpVYI0Lq/WrQA2mdPUXP4sAQe994L9O8vcxNu3KgtbApIAJSzBsjFRYIodbJDSwRAeWaAsgOg2HPyZVwJ8XDyr2oYBW8IgLy9tWhQXVlWzQBVry4jxRQl98SFhaV2f9WvL32Q0NqWXwbIeF6jZN86xateL2OJifJ5+7vFAwBSM52kYJ4ZILJhDICI7IxOZ5hMGfHx8t28bBmwcKEcmzNHanrUAKhVK6BZMxlWf+uWTLqofn+/8gowZYrsqxMoSwAk+2oAlJOlAyCTDFB2F1jsRRlGVQ2xQPXquQMgQKJBtUoc0AIgnU4bJRYeXrgG5ZSz/gcoVBeYD+IN65ulKC5SXGXj1AxQgIv24SUnI+8M0DvvyGK35aWPjyokBkBEdmjIEG1g0oQJUpszciQwYID0+IwdK9kgQAIgZ2fJBAHA99/LtmdP2Z4/L9u335bt5cva97paA5RTzgAoZxF0Yb4XC8oAXb8qfXnVEAv4+ZkPgAAphlJrflq21I6rhU+hoQU3xhxzAVBeRdBGAZAnkgzzGiXDXarKbZxaA+TneAM6ZAHI/nzMFUGfPi1DEcePByZN4kKpZDUMgIjskF4vNTlz58o/xgFJeixZItmYf/6Rri1AAiAAaNdOe/1990nPjDovYefO8qMGNuqoIPX7L6f8MkCZmaY9Jt9/D1SqBGzZYvoacwHQ7dswBByxZyUtkTMDZDISDJCusH375A2Mp9RWV50NDS1epiK/DNCNG1LlbLRMh1oD5OWaAXd99szWcJdK9JwzDdoYNQCqhHh4QD6Y5GSY7wJTI2YAWLwYeOih8jXpEVUYDICI7FTLlsCrr5p2U9WooXWFGZ8HaAGQg4Oco9cDK1dKT8a338pzjRqZvrYoXWBubpJpArRuMEWREWoJCcBPP5m+Js9h8E2bAjNnIhbyJr64nncXmMrPT1aPNda9u1w4Orp43WDmAiD1RgEpsDaXAfpgLtzqyISOKf71ZD20v/8u+vsX19q18ksvQtB365YEvN7KLW1W7tsw3wWmdv8FBkpx2M8/Aw8/XLIF64iKgQEQEZkYNQro10/2a9bUCpeHDJFi6HfekVUpAPn+GjdOltYCShYA6XS564D+/VfqkQBtTkFVnhkgAHjrLcTeL+mpaogFataEv788ZTYAMsfFResGU9NhhZWRoS10ZhwA6XSmdUBqAOTnpwVANbzh7iH/a05ukh11llU3mKJI19Qrr5hOA14ANQPknRlnyACZdIEZZ4DUACgkBPjzTwkIQ0PlD4/dYVSGGAARkQmdDvjiC/nuf+kl7bifH3DgAPDCC3m/NmcApAYmOfn4aAOjHBxyzxitBkDffae9Jr8AyCQDlC22ZhsAQLVuzYHBg/PPAOVFjQQLEwClpUG3axd06enSzZORIV/u2UXZBsZD4c1lgDyNapoatpadsgqArl2TyngA+O+/Qr/M0AWWfsO0Cyy/DFCtWpJlW79eFrj94Qdg2rSStZ+oCBgAEVEuNWpIjc+zzxbtdY0ba/suLhnGS3eZ0Ou1zJKa/QFMA6CsLK3gGpBpddQAJz1dfoA8MkDQFnmvNrov4OlZvACoTx/Z7t9vOtY/PR3YtEkCk1u35Eu8eXM49uyJNosXQ6dOcd2ggRbpqdRC6FmztOH3RjVAnp5aL1lKUHal+t698gspbcZRZs6IMx9qzVeljBumXWBGGaD9+2W5lMhT2R+cGgj27q1NJLV0adncJxEYABGRBRlngFxd8+/OULvBjBdKNQ6AduyQZEGlSto5almNcaCTZwZIDYCy36dYAVCtWkDr1tI19Ntvcuyff4AOHeSLu3NnadyQIYZ1PQK3boXul1/kXOPuL9Xdd8tWLQauXBmoUsWQAfLyMsoAVQ+S+Yji4ooUkBRbsQMg2XrfickzA7RwodRxff9fGzmmBkCAFEI7OckHe/Fi8dtfBmbNkvmvqPxjAEREFlO/vpbNcXXNyPfc/AKgy5eBr76S/YcfBpo0kX31O1kNgBwcpHDaZBh8trwCoMTEIq6zpXaDjRsnqbGOHWUKbR8fLZvj6gq88gqy+vWDTlHgoE6waC4AmjhRXv/rr5Lx+OsvwMHBfBdYmqM2C2VZdIOVMACqlBpjPgN0+7Yh3rse5yQ7xgGQk5OWPlSLviAzj6u9hLbgxg0Jfl55Bbhzx9qtoZJiAEREFuPmps0lWNgASA16jPdffVVGmAHAiBFaZilnAOThIQGXuelmcgZA3t4SpwBFzAI98YQ2CVJ0tHTRDB8ujbl0SbIzsbHA668j8803oagRIGA+ANLpZG6B/v2l4LhtW2RkaF+oJl1gKQA6dZIH1giACjkSTJ0IsVLK1TyLoNVl1WJTs7NCxgEQILNtAsCJEwAk2xccLMk1W6GWRymKFvRR+cUAiIgsSv2HfHG6wPr1Mx051rkz0K2bdk1zARCQOwOUnq59Kavvo9MVsxusXj3g6FFJHe3ZI9mb774DfH21G1Ab0qwZLt57r/ZacwGQGcaDpEwyQMkAOnXCNVTH7b/2aQu1lRbjACg+Xosi83HnDpCWll0DhFumXWCVKgEA0hJTER0twVQsqsnvK/s5gxwBkFpGVYTBaKXOOOhhAFT+MQAiIotSszUFZYCqy1Q3JhmgBx6QOCMzU6aF2bVLurnyywAZb9Xjam2xXm8aYBUrAFJ5eko2Rp0ZMg8nH3sMipMT4OioTbdtJDkZ2LBBK+IGtADIyUlG3xsHQNdb9EBdRKLnuaXA/PlFb/fp04Xr88vM1KIONVVWiG4w40DAC4lwd5VA5/ZtSJBYuTIuoSYURYKkWFST7I9xpgzQ5lbI7gJTRwImJtpOsMEAqGJhAEREFqV+j3l75z+x3YgRMsjqiSdyP6fXSzCgfkeqAdDJk9L9UFAGSE1cVKkCk5FoJQqACinZzw+Zf/4pNT5qlsjIu+8CDz4ocw2qcq6dZtwFdvyyD1LgjsNoi6w582TW6sLIypKK3UaNgKFDCz7/wgVt9fouXeRYIQIgNdPm7nQHDsiCh78XgOzPIru77wLqGM43BEA5GWeAFMXQ3QRoK4dYm2kApMv7RCoXHK3dACKqWEaNAmJiMlGt2kkAfnme17Rp4ZfZatBAtnFxkt3JKwBSj+es/1HluRyGhSn33CMRnBlqKc+6dbLwLJA7ADIO6K5ckf10OCMuyxtVR44EDh+W4WLGUlOB11+X/bvuAlatkvVOAJnH6MqV3HMSGVODnQYNpOr8r7+KlAHy1ss4fvdaVYDzRvVYrVsjanu84fwbqKoVjxtr0ECyZklJwKVLiIsLNDx1+bLZZFqZM16R5NatPD9iKieYASIii/LwAGbOzELNmkkFn1xI7u5acbXxavM5u8DU+YHyCoCKPBt0KVAHOR09qo34Np4DCDANgIyzH9f82wBnz+ZerwSQ4OfNN+Vn0CAJfpycJNuiKMDq1fk3TA12GjXK3eeYD0MBdJbseNSVvk1DAJQjA5QIb6T610Euzs7a+x4/bpIBUudOtDZ2gVUsDICIqFww/k7OKwMEZNfNZM9ZmFcGyFoBUHy8aUDzxx+yNZ4DCDDtAlMzQABw9fGZsvPpp6bjsI8d01a1HTRIRq21aCFLTczMfs2qVfk3rpgBkBoI+KRL1OnRULJMhrKj1q1NAiAAuOFT3/zFjLrB1BogwDa7wBIT2QVW3jEAIqJywVwApGZMXFy0CZeTk7UMUM4SHGsHQEZT3AAAfv9dtvl1gRl/+V9tcq9kdK5d09YJycwEnnxSRogNGiSzUh89Kj89esj0yw4OwMGDUkSVF3MB0OnTBc7MrGaAfBAPxccH7oEyxbchA9S8OaJyBECxHmYyQECeAZAtZoDU+6byiwEQEZULxoXQOTNAOp1pHVBBNUDWDoACAmQbFiaj3QpTAwQA1244ApMny4MPPpDg5803pTDaywv47LPco6t8fWXhUcB0bZGc1Gm2GzUC6tSR7rPU1LxnZs7IADIyDIGANxKgtG0LD0+doe0AADc3XHBqYPLSWBczNUCAyUiwXEXQ6ekyM+JXXwHnzmlPRkRIm9UMWDF9+y2wYEH+5xjXALELrPyzegC0aNEi1K1bF66urggODsbOnTvzPX/79u0IDg6Gq6sr6tWrhyVLluQ6Jz4+HpMmTUJAQABcXV3RtGlThBa22pKIbJI6F1BERO4aION94wxQSYqgja9jKWoA9NhjMg1AUhKwe3f+o8BMMkBXIdkeb2/5RbRrB7z2mjz59tvmi4sBGXIHSDeYuckN79yBYabCRo0kY6RWnpvrBktOBtq0ARo1QkJMCgCZA0hp2zZXQXpWFhCVKd1itSDBVKxDHsXxJhkgrZ2XDl2Tew4OBsaOlcyW+kubOlWCt6VLzV+zENLTZTTilCn5d7exBqhisWoAtGbNGkyePBmzZs3C4cOH0bVrV/Tp0wdRUVFmz4+MjETfvn3RtWtXHD58GC+//DKee+45rF271nBOWloaevXqhfPnz+Onn37CyZMnsXTpUtTM638MRFQuqMthRERoNcDGAZBx1qSgIujExOxZlvPx8MOSCImMLFm7jakBUIsWMucRIN1gamZBrQEyDiJMaoCuQgKB//1PDvz7r8zZs2AB8PTTeb/xoEESVZ0+DTz+eO71Jc6elcCoUiWt3zC/OqD58+VmIiNx9ffDAIAquAmlTZtcczJdvw6kZjlDhyy0QTgA4EaaV+5rAjJxpIMDkJCA+BvaRJqXruglSPPxkZ+oKBlCt3mzVkh19qzpjJJFcOmSZOIAmew7LxwGX7FYNQD68MMP8cQTT2D8+PFo2rQpFixYgMDAQCxevNjs+UuWLEHt2rWxYMECNG3aFOPHj8e4cePw/vvvG85ZsWIFbt68iQ0bNqBLly6oU6cO7rnnHrRu3bqsbouISkFQEDB3rmRJ1EkEjUeCG3/x5hUAeXtLvRCQfzdYYqLUDycny9ZS1ACoeXOgb1/Z/+47WVgeyJ0BMv5iNmnzlCkSLHTrBoSHA88/n7vry5inp5Yp+uorSaf98IP2/MGDsm3UKPfkS8eOmV7rzBmZzCjbkcOSqWmJo1Datcs1J5OaWKqBKwiARBexN/Joq4uLIfMUd1PLAF1XfGXkWGysVsy9YAHw1FOmr8/Z1kIyDnKv/3dDrmsm8DMtgi7WW5ENsdo8QGlpaTh48CBmzJhhcjwkJAR79uwx+5q9e/ciRO3Lzta7d28sX74c6enpcHJywi+//IJOnTph0qRJ+Pnnn+Hr64vhw4fjpZdegoPxjGhGUlNTkZqaanickP1Xnp6ejnTj6VotQL2epa9r63jfvG9LmDlTEh1Lluixb58OAwZkGoIhNzcHAHokJGQgNtYBgA4+PhlITzft8vHzc0RUlA6XL2egZk3za13t2aNDVpb873HXriw88UT+y3qo8rvvmzeBq1dl4piGDdNRty7g7u6IK1d0hiyPm1sm0tOzsueXccrVzRIdrSA9PUOyNMYV1enpuHIFeOABR/Ttm4W33zZTuDx1KnRdusDh2WehCw+HMmwYMlNToTRrBsdnn4UOQOY99yAru+26u+6CIwBlxQpkjBsnXV4AHJ5/Hvq0NGTdfz+y0jJwZEdLAEBz5/+QXqcOnM+mA3DC7dvS1rNndQAcUQcXUA0SmcbEyH2a49C+PXDyFG4lmf7/+mKfJ1AnKwu4/344PPww9D/9BJw7B8XLC0qjRtAfPIiM8HAowcFmr5ufM2ekjQBw9YsNwM4vkJWcjMwVK0zOu3VL/sYAID42A/5//430rl1zz8lUgdn6/9OK0i6rBUCxsbHIzMyEn59pX7Cfnx+u5tFBf/XqVbPnZ2RkIDY2FgEBATh37hy2bNmCESNGIDQ0FKdPn8akSZOQkZGBV1991ex158+fj7lz5+Y6vmnTJrgbj6+1oLCwsFK5rq3jfduX0rrvVq3k5+RJbWDTnTudAfhi9+5wXLvWBoAjjh7diuvXTZeBcHXtCqAKliw5hdjY02avv2ZNIwAy895ffyUjNPSvIrXP3H0fP14FQFf4+iZj5055/r33PLF/vz+OHauGmzddUa3aIYSGJuDKFQ8A9xte6+iYhYwMPaKiUhEaaj4l9e23TfHff41w+rQObdpsznsm7tmz0XrJEgSFhUE/dizSPT2hS0hAbLNm2Hv33chS6yUdHXHXXXch4O+/cWfIEOx4+23U//VXNAkNRZajI7Y++CBiLjkjcYc3nJEK//rpCPvrL8TEuAEIQWJiJkJDQ7FpU30ALRDoeBlVM2SNkn//vYLQ0ENmm1cpOBhtvvsNSnagUROXcBm18Lt7Q9TObptL3764LzQUTsnJiBg0CE5JSWh48CCifv0VR9UK8yLYvLkJACkyu3rgPAAgaccObM1ROxod3ROABDsJh8+g499v4ejVqzg3cGCR37O8s9X/pyUXZtmXbFafCVqXI22rKEquYwWdb3w8KysL1atXxxdffAEHBwcEBwfjypUreO+99/IMgGbOnImpU6caHickJCAwMBAhISHw9vYu1n3lJT09HWFhYejVqxec7GgaUd4377u0ffGFA44eBZKT2yI1VbIHDz98L3L+J3z5sh6TJgHff98U48Y1wj335M4CLV6sZR+uXvVEcHBf+OVRt2ssv/u+eFG+0Nu3d0Vftf8LUtOsuQdA7mHfLVvqcPgwkJDggt69+yJnMjsjA3j6afnfeWamHnFxIXjssXyGr/frh6z//Q/6r7+GS0IClBYtUGnLFjxgvHAaAHTsCKVdO3hduoS+Tz0FXXZhj/Lii+j25JNYv17+v9scx5HUpD569eqF+Hi577Q0RzzwQF+Ehcl91wnIQLWLkgFycamJvn39c/zuZCJonQ6I2ngC+AtwQwrq4ywuoxYq3/0w+vbVPitd7drI3LEDDadPh+7HH4ENGxCUmIhAo99tYa1erf1Cb96RPxivS5fQt3t3k0IzRdG+MhPT5R/HTW/fRpNivGd5Zev/T0soQnW61QKgatWqwcHBIVe2JyYmJleWR+Xv72/2fEdHR1StKnNPBAQEwMnJyaS7q2nTprh69SrS0tLg7Oyc67ouLi5wUQsDjDg5OZXaB1ya17ZlvG/7Upb33ayZLK2hBi9OTkCVKk65SmOefloWWf3+ex2GD3fEoUPasHRARi2py215eEhN0YEDTnjwwcK3xdx9//efbFu00MPJKf/yy5wLpbdpo0N4OJCVpcOtW065grHQUNPi3VWrHPDcc+a7/A1WrJCutH//he7LL+FkZt0yBAQAK1cCDzwgwY+/P/D++3AYPhwOOp2hF65VZw+cevhhBDk5wcdHu++MDCfDKPqgDtVR7aJkgG7eNP0dxMfLUhddugA//QQkPPEC8BfggzjUhAzLunbN0XTpifvuA+67Dw6AjIYDoD96FHo1iioC43E31yG/B11WFpwiImQB3GwJCVoAlgAJlBxOnYLOFv/bzsiQ30MepR8lZav/TytKm6xWBO3s7Izg4OBcabSwsDB07tzZ7Gs6deqU6/xNmzahffv2hpvu0qULzpw5gyyjybtOnTqFgIAAs8EPEVUM8+cDH32klWP4+Zn/HtTpZMR0ixYyqqpxY2DYMG0w0X//ySR37u7aGqJ5lCUCAHbsAIwGoubJuAC6IDl73mvX1gZnmasQUEeAjxol33f79xdiEmcHB+D996UCO79Rsr17A998A7zxhvxyRoww/GLDw+WUVg81QEZ2pkRdSB6Q4FENLmqPux/V/pK1yXJOL3DokNxXaKgMRovzkyF/lRGHWpB0WL6TITZpIumj+PhizZpoXAQdg+raH5FaHA4JjI1nf07QV4YCSB9sAZNFlrnUVIkm69Yt9sg4e2DVUWBTp07FsmXLsGLFCkRERGDKlCmIiorChAkTAEjX1OjRow3nT5gwARcuXMDUqVMRERGBFStWYPny5Zg2bZrhnKeffho3btzA888/j1OnTmHjxo146623MGnSpDK/PyIqO47ZcwSePAlMmybBUF48PGQx0gYNZDTP6tWyMv0PP2jBTseOMsgKyDsAunFDhrM//LCMSM+LohQtAHJxMQ3eatbMexLHS5e0GaVnzdLmPPz224Lfp9BGjpSL50hNHTki29attcyIXm86jF8dBVanDlCtjgRJOQMgNUhKSZEYRp0F2kefgFqNZWicOj/P2bNmRmC5uGjzJOT3QeQUEYGUbr1Nsmcxen9tdNkhrU4pZxyRmaVDkoM3dMnJeU8WWVamTAE6dsSt45cwfTpwfPJS4O+/pV2HzNdakZUDoKFDh2LBggWYN28e2rRpgx07diA0NBR16sg06dHR0SZzAtWtWxehoaHYtm0b2rRpg9dffx0ff/wxHnroIcM5gYGB2LRpEw4cOIBWrVrhueeew/PPP59rtBkRVUwBAcB770lQkp+GDSVY2rtXJiYEJIBSM0GdO8sPAPzzj/yjOqcVK7T5hDZsyPu9fvlF5sNxcSncquY6nTYUHpAASJ3DKGcGaMUKSUB06ybZrFGj5Pg335RuYiIuTgtuWrY0raNSy2auXtWCmdq1tWkJbt82nYfJOH64dAmGWaAr3xeMmq+NNxzftk3L2OXSqpVs//1XIs4tW2ToXX4+/BAXdl4wORTjEgjcI7VYxhkgNehyQAb0OvnFRvs1lIMREfm/T2lKTpa14f7+G293/x3vvw/M+9yojzTn+itkYPWZoCdOnIjz588jNTUVBw8eRDf1n1wAVq5ciW3btpmc3717dxw6dAipqamIjIw0ZIuMderUCfv27cOdO3dw9uxZvPzyy3kOgSci+6XXA3ffDXz5JVC/vtTRqN1ZnTtLhsjXV+biyfkP6cxMYNEi7fHPP5t/j5QU+Qc6IJMWG0/emB/jbrAaNfIOgNT2PvGEbAcNkh6c8+elK6y0qImWOnWAypVNn1Pb/uuvsg0KkjmYvL0lUwdI9kxlHABdvmyUAarujFr1pHTh0iVg9mz5vW/aZGYiS+MAaM4cqRFSI1tz0tOB9esRiboAgEqIBwBcz6gMpa3UFOH4ccOiswmnrmafd8tQWH/VN3u2bLXAyxoOHQIyMqAA+OFGTwDAeaW2VvvDAChPVg+AiIiszdVV/hFt7O67JROjZoFydoOFhkqQUamSnHfokHyRKwowfboeDz0kvRDvvy81JjVrAi+/XPg25cwAmesCu3ZNC0TUgUju7sD995tvsyWp9T/m5phVgzx1vVa1gFynA7LHq5gEQMZFyCYZoMpaedLFi1K8Dkjskiu4aynzESE0FJg3T/bDwkyyOCa2bwdu3MB5jxYAgPbO8ou8k+6IJJ9aEvlmZsqisgAS/joAAPB2ToV3JfnqvFZNgierZoCyK/YPNx2Bc6gPALikC5RZQwEGQPlgAEREBKnlUXvTmzQBqlSRfTUAevNNCWayEwKGgOmpp7SBQhs36rF/vz8WLnTAunVSR6R+D73/vjbTc2GoWRQnJwkazGWAtmyRbZs2prNeq3MBlmb5h1r/kz0/ogm17WpgM2SI9pzaTuM6oLwyQJUry33rjb6p1P1cy0aqGSB1GLRar2S0UoCJn34CAETWl2ix+fjO8PCQrryY6zrDyDI1gErYJQGSl4/ekAG6Xqm27NhAAPSj/zOGQ9EIQHrP3vLgxAlrtKpcYABERJTtk08kW/H669qxceNkxFhcHDB9uixi2rq1dMPodDKsftAgOXftWh1WrpQq51at5Ms6MxPo3l0bUVZYahBRo4Zcx1wAtHmzbNWMj0oNgPJKflhCYTJAgGSujEaS5wqAFCV3BsjQBeYjXWbqvbu4AGo5Z64AqGZNrS/u7ru19UV+/FFSdcYyMqQKHkBkJbmBug0dUb26VJ7HxEALgA4dAjIzkXhQhtV5+7kbYqvrXrVkx8oBkALgx1PaB6EoOkT7ZBebxcRYflXfCoIBEBFRtoAA+V40LqCuVk2+7FesAGrVkmJYtdtp0CCpb1EnAt6+XY+rVz0REKBg92457803ZZRZEaemMXSB1ZCF1HN1gSmK9PAAuQMg9bv71KnSWbMqNVXrWSkoABo82HQqmpwB0K1bpiOscnaBAUBgoGz/9z/TqQkyMozeVKeTCLVrVwl67rpLfjGZmbmHBO7cKVXpVaog8nZ1ADJiXJ1qICYGWhS5fz/w669ISJIP0LumpyEDFOfmp91MQUGGosgfwoED+Z9XFJcuAZcvI1wfjLOX3eDqqgWLF296yB8nYHvdYBcvSso1r+xcGWEARERUAAcHWUT93DkpCQkNBb7+Gli2TJ5v0kRbOxQA5s3LhKenDHl/+WXtS6ko1AyQWgOTMwN05ox8jzg7a4OWVNWrS7CmKFqmxpL++UcKw319gXr18m47YNr9BeQOgIyzP0COImgf2c6eLaPbXntNsnE+PjKS7PBh09eG95mJleN2QKmZnZmZPl22ixdLGmrECOCVV4B33pHjgwfj/AX5GqxbV35vgMRGhijy33+BBx80THzoXUlvyAAlprlByR61XGAh9O+/y/C1++6DYfG3ksouhPrRdyIAqQNT/w4vXYI254IFu8E2bdLh1Vc749y5Elxk2zZZZTi7G9JaGAARERWSk5N8AffpI1/IakEvIJkOAKhXLx6jRplfZLUo8gqAbtyQImC1+6tzZ/Mjy3KUsFjU9u2y7dbNfGZLbY+PD3DvvabP5SyCVut/1Ps1lwHq108CzqpVpTuwSxc5nrMbbORICVT37s0+0KuXBD7p6VIrs2qVpOT+lPXUEvsONbQjKEgLgGJisg8MGCA3U6UKEioHAdBGswFASoojFHX+oYK6wdRsR2KiDAe0hOz6nw1pfQAAjz4qgS+Q/XtVAyA1A3TyZO6osYi++EKPf//1xbp1JQgf1D+g7t1L1JaSYgBERGQBM2cCL72UiRdfPGBStFtc6pes2v1TpYrWlRQTk3f9j6o0C6F37JBtXt9fatsHDJAMlbGcGSA1AOrQQbZxcVqCJOfSZKquXWVrHAClpmpJGMN3vE4n2YZ//pFusXfflaKtBx4Axo9HZF0ZNl6lirTZJADS6WQCp6Qk4MYNJIyXoMXLS7u/5GQn0wAoMlLmRsiZ1jp0CNi6VT5AvR5Ys0brv8zPk09K5KtWnCuKtL91a8lM7duHDDjg1C0/w+9F/Xu5dAmyPgwgAdD16/JLbtdOCqlM+g8LLyYme3ssRmYH/9P84rz5Uqe3sXIAZPXFUImIKgIfH+D117MQGlr41ajzM2WKZEVGjpTHer3UAV25It+v6giw++4z//rSygBlZAC7d8u+0bRtJp56SgIcdQScsby6wFq0kDjl9m1tIFfO+YVUagC0a5fEBDqdzBCdmSnHTUpenJ0lGlQjQiOR2XM31c0ezW5SA5SDWkvl7a0FosnJjlAayyry+PFH4PPPZWLC556Tavrp06UW6YMP5JyhQ+UX8PHHwMSJMk9CXje5e7fWx/roo/JBLl4MLFkix3r0AG7fxmXURGaWHs7OEiuZZIBGGmWAPvpIu4l33pHrff+96fDBQrgelQrADTGrtgCYLXNInD6tvfHly6ZRYk6XL8uHpdfn7rstY8wAERHZoHbt5PvUeOFTtRusRw/pJvL2Btq3N/969fv+v/8kqLCUw4clKeLjI0GLOc2bS2+TGlgYyysDVLt27iXJ8ooN2reX793YWC3rY1yCU9ia39OnZau206QGKAc1KDPuAktOdtKW4Lh0SYKf2rUlEvvpJ5kH4aGHJOMDAC+8IEMMAwKkiKtuXZm08fRp6aZTKQrw4ova41OngP79Jc0ISJrn5k0gNRXnPWX+o9q1JaYwyQCp045fvw4sXCj7EydKt97mzfJHUpQIOSsLMVclyryqz56d884dbd6lrVvlnmrUkAg+ZyYM0Lq/2rXLO0gqIwyAiIjKCfXLLTVVvns++kibWTmngAA5JytL60ExRyliuZLa/dW1a/EWGs8rAxQYqCURAPkyz2veJGdnSawA2oSIOQOgwtzX1q2yVa9l0gWWg3EApBZBJyc7QmnVSjIeXl6SnYmMlO6pMWMkNbVunQREPXpoX/rr1kn0eOuWpMkaNZJhf61ayYJ0P/8sw9zc3CR4cnCQwCEzExg+HDh2zJAGu9BAuvHUWmyTDJCHhxbdJSfLZJGffCK1Qw0byi+/SxcpsCqElHW/IzFLPpSrDbNH2wEyRHLnTinyTk+XiHvBAlm3JOeoNxvp/gIYABERlRvz5kn97G+/yRfcuHH5n5/ffEBXrkj9UL165gcwxcbK+6lZEpUaAOXV/VUQNctz+bIEGsYZIOMAyMcH+dZSqZkv9d5OntSeu3HDfBBjLDVV+y7unT1nYGECoJw1QPD2lgzNhQvS96fXS6CxcqXU/tx3n0RyapYEkHmKjhyRAOLuuyXQUWedHjpUurwAyaI8+qjU2gCSbfr8c3nPP/4AFi/GhR6PA9BGvKtB8tWr2UkltQ4IkCGJer0EX3//LUVaqanA2LFGleN5i3lfC5SuxTpIF1b//tL2nj1ljobmzWUNlA4dJDv0yiumF7GRAmiAARARUbnRqpWUk/Trl3fmx5gaAH31lbzuxx/lH/9//inP/fWXzBE4eLD2BQ9IIfL998uwc+MgKytLKzwu7vdXjRoSvGRlSXsuXZLjgYGmXWB5FUDnvLd//pFtziCuoG6wXbskKRIQoK2iodYAXb+eeyFZcxmglJTsD8Hf33x/XZs20tWUkJC73kWvlwmn9u6VjMmlS5INcnOTyKVqVa0b7KWXpCbo77+1tJi7OzBhAs7fkvdVM0DVqkmGTFGyi8nVkWANGwKPPKK9v4+PrOA7fLicPG6cNs256soV+WNJSgIOHkTMfm3s+40bOgmw3nxTMl0ZGdKmH3+UoOiHH+SPdNMmw2g1REdLsKjTaYVcVsQAiIioglJnYD54EJg2TZIJnTrJIKirVyURUKuWZE9GjZIv/cREGeavdpvt2iXfu4D0vMTFSc9K27bFb5e6Ruknn8h3vV4vgZFxBiiv+h+VmgEKD5drqAFQ/fpaW/OjDl4KCdGG8qsBUGamNhRfZVwErWaAbt92yv9NVAXNgqnTSfT36qsSILz6qnSDqZGWuiidl1eul17IXsxeDYD0eu33eOkSZPbI3r2B5ctz91nq9fIh+PvLL3DOHIn+vvlG/kgCA7XtmDG4Bj+Tl8fEQKLyJ5+Ua33xhVZ3FBQEjB4t++rU6mr6sE2bgiPcMsAAiIiogurdG/j2W0kkDBsm5R61a0uSYfRoST6sWydLTPzyiyQXqlSRupoqVaRXA9AmUv7hB9l26VK4DFRe1B4etduqRg25XlEyQA0aSDxw547U8iQkyHewOh9TQRkgNQBSu78AyZyo75uzG8xcEbQhA2RJtWpJJkid7KgAagCkdoGplwCyA6D69aW7LK+MS5Uq2siyd9+VqvvRo+UXlJUlUWF8PHD8OGJQ3eSlhoV5Fy2SByNGmF775Zcl6FJnDv3ySzluA91fAIfBExFVWDqdfCfl/F5Sh44DUqqxdCkwfjyQkiLHqleX7ywHB8n0/PijdInNny/PjxlTsnYFBkqPkLq6u1q3UpQMkF4vNcXbt2urztetqw3/zy8Aio6WOmWdTuZKNFa9unzfR0fL97peLwGgcQ2Qq6vsp6Q4IiurePPpWEJWllZErmaAAO33abzIbL4GDZKusFWr5HGbNrK+y6hRUiT2yy/A558jJuURYLv2MsO6dA4O5ofT168v1/3mG9M/mrzmbihjDICIiOxMzh6ZUaOk2+vWLckG+frKFpAs0JYtEiAB0tsxfHjJ2zBsmBYA1c5eVN04A1RQAARIN9j27YZ1TdG4senkx8aBnjF1ndTg4Nzf276+0gs1Y4bW9TdunNQKA5L9UQMgRdEhKUn7XZW1q1dlSRIHB9PfnUkGqLBWrJBJp1q31hagUw0eDAwejJipMB8A5efVV2UZEAcHyWrdf7+s2WEDGAARERGqVTP/j/ipU7VJFzt0kJIRS3j4YeDZZyWLoWYsqleXrrCMjMKViKiF0Opiqk2aSBCk12tZnJzf5YD57i+VOhJMDX4AGXWn8vKS73InJwXp6TokJJguiVKW1EXua9Uy7ZIscgYIkCiuT598TzF0eeXx2KwGDbT+xKKuCFzKWANERER56tNHhrwHBQFr11ou21G9utb9pC7gqddrmYzCZIByTu7cpIlkZxo0kMfmusFOnpRR2kD+AZBxG9Tz3d0l0NDptDqgW7cKbqfq9GltDTRLyFkArSpWBqgQ1DimalXpKy1UBgiQX5iNBT8AAyAiIsqHXi/dTGfPapkFS1m+XObLUwcLAVoAVJgMUIMGppMJq5My51wDVHXrlpS7JCVJTbC5OmP1Hps10+YHVCdbNH4vdT8xsXBf7CdPyqi7Hj1yD7E3FhsrNcJvv13wNfMKgIqVASoENQCqU0cKogqVAbJhDICIiKhAlljgNaeaNYHnnzfNKj38sGRhCjPRoloIrcoZAK1aJQXc//0nI96GD5dApFYtOW7unp56SuYd/OMPqX9yctJmlTYehV7UDNDatVKvc/SoNgGjOd98I6PFZ86UIuz8qF1gxiPAAC0DZJgM0ULUgCcoKMFw/fKMARAREdmMKVPki1UNYgqidoNVrqzVMKnzHx04IEPumzaVaXRCQ6WLbMMG0zXWjFWrBsyaJVkUd3dtmQwgZwZIoiLjCSTzY1xHtHRp3uf98ou2/+yzwMaNeZ+bVwbI11fuU1HMz/JdHFlZ2hppdepI1McAiIiIyIKKUi7SubNs27TRXtenj0zAPHmydGV5e8sQ+U6dJBNjZmH4PBlPWWOuC+yHH/Ro2VImP05ONn+NmBhtMmRARq2ptUCRkdpitTdvajNtDxggQcfQoUBEhPnrmpsDCJDfQ0iI7C9fnu/tFdrNm1rXHbvAiIiIrOzBB4Fly4DFi7VjOp1MNfPRR1IHdOsWcO6crC9a1BHYBQVAP/+sx7FjkqkZOlRGsOX0+++SjWnbVn7S0qSr6+23ZZqd7t1l9unff5dty5YSqPXsKcHRmDG5r6soWhdYzgwQADz9tGy/+irvwKwo1GCnShUF1arJkhnx8blXzyhPGAAREVG5pdMBTzwhw99LQ+fO2goSxjVAdetKF5i/v4IZM6TL6bffZOWJnCvRq91f/fvLPEqAdLPNnCn7Bw9KoKJ2fw0cKLVHX38txeAHDgDvvGN6zdhYbeJKc8XpISESXMXHA6tXF+vWTagF0L6+gIdHOpydFZPjhfH55xLUbd9e8LllgQEQERFRHjw9tS4z4wzQyy9n4fXXd+PkyQzMnw+sWSNF1V9+CUyYoGVs0tK0eYf695dCbDc3LSvTo4dsZ8+WwmtAAiBAisQ//lj2587V1mcDtO6vGjXMT02g10tBN2CaHSsuNdDx81Og02k1VIWtA4qNlfqurVvlnl98UZtc0loYABEREeVDnR/QuNbG2Rlo2TIWbm7yeOBA6YpT1wR95BHJ0OzYIQup+vnJzNWVKgHPPCNB0MqV0u0VFCQLryckyLqk6kKvgEzOPHiwjOYaNkxblFUNhsx1f6kef1za+c8/8lMSaheYumBs9eqKyfGCfP65/D68vSVD9t57UmBuie654mIARERElI8ZMyRQefbZ/M97/HEZXu/iIiPNPDy0yR779dOG3b/7rtQljRkj5775pnaN/v1Nh+frdBI81KghxdDjxgGHDkmBN5D/uqK+vjKtACArUqhdc6mpcj9Fqd8xzgDJVh4XJgOUmgp8+qnsL1okC937+spcTO7uhW+DpTEAIiIiyoerK/DAA9oaYPkZMkTWGvP11QIOR0dg7FjT85yctP3HHpNlRgAppM6penXgp5/kNT/9JBM4JiVJV9KcOfm35+WXJcj6/XcJQpKTpRC8b1/ghRcKvh+VcQ0QULQAaM0aOa9GDcmMDRwo8yG9+27h3780MAAiIiKyoG7dZBmK6Gj5uXlTsh150eulTmjvXlkr1JxOnYCFC2X/zh0ZKbZ+fcFLkzRvLt1NADB9ura4LSBD5Atbw6N2dalLhaiZIHNdYOnpUrs0ZAgwbRowf74cf/ZZ6ZKT11s3+wNwMVQiIiKLc3aWep7CqlwZuPvu/M+ZMEECjn37JHipVKlw137mGQmwNm6UZT28vCQbc/KkBFVqgJIfNQOk1v7klQH66y8JdHLOXeTuLiPkbAkDICIionJApyu4yyuv1335pRQdx8fLjNjXr8u6aIsWSY1TQcGUFgABcXG5M0AZGdLdpmabqlUDnntO3ufkSenmq1Kl6G0vTQyAiIiIKjhfX21xWHd3mdW5WTPgxAkJXGrUkIkVR4/WuusSEmS0WZs2xqPAlOwASB6Hh0vG5+hRbX6fp5+Wwu7KlcvwBouBARAREZEdMK650euBl16SkWjGi64uWyaTNQYESB1PfLwM2VcnXfTzA06dApo2VeDpKcXY6ggvT09gxQopdC4PGAARERHZoWHDJOA5fRq45x4pqP7uO9PFWr28tLmHvL0lyAGki+vsWVnZfs8eyRZNny4Lz5YXDICIiIjskJOTTNRo7KmnpHbH0VEyRA8+KN1cGzbIBI3GC9VWrw48+qj8lEcMgIiIiAiA1P8cPmx6LDhYWw4kPb3s21RaOA8QERER2R0GQERERGR3GAARERGR3WEARERERHaHARARERHZHQZAREREZHcYABEREZHdYQBEREREdocBEBEREdkdBkBERERkdxgAERERkd1hAERERER2hwEQERER2R0GQERERGR3HK3dAFukKAoAICEhweLXTk9PR3JyMhISEuDk5GTx69sq3jfv2x7wvu3nvu3xngHbv2/1e1v9Hs8PAyAzEhMTAQCBgYFWbgkREREVVWJiIipVqpTvOTqlMGGSncnKysKVK1fg5eUFnU5n0WsnJCQgMDAQFy9ehLe3t0Wvbct437xve8D7tp/7tsd7Bmz/vhVFQWJiImrUqAG9Pv8qH2aAzNDr9ahVq1apvoe3t7dN/vGUNt63feF92xd7vG97vGfAtu+7oMyPikXQREREZHcYABEREZHdYQBUxlxcXPDaa6/BxcXF2k0pU7xv3rc94H3bz33b4z0DFeu+WQRNREREdocZICIiIrI7DICIiIjI7jAAIiIiIrvDAIiIiIjsDgOgMrRo0SLUrVsXrq6uCA4Oxs6dO63dJIuaP38+OnToAC8vL1SvXh2DBw/GyZMnTc4ZO3YsdDqdyc/dd99tpRZbxpw5c3Ldk7+/v+F5RVEwZ84c1KhRA25ubrj33ntx/PhxK7bYMoKCgnLdt06nw6RJkwBUnM96x44dGDBgAGrUqAGdTocNGzaYPF+Yzzc1NRXPPvssqlWrBg8PDwwcOBCXLl0qw7souvzuOz09HS+99BJatmwJDw8P1KhRA6NHj8aVK1dMrnHvvffm+ht47LHHyvhOiqagz7swf9cV7fMGYPa/dZ1Oh/fee89wTnn7vBkAlZE1a9Zg8uTJmDVrFg4fPoyuXbuiT58+iIqKsnbTLGb79u2YNGkS9u3bh7CwMGRkZCAkJAS3b982Oe+BBx5AdHS04Sc0NNRKLbac5s2bm9zT0aNHDc+9++67+PDDD/Hpp5/iwIED8Pf3R69evQxrzpVXBw4cMLnnsLAwAMAjjzxiOKcifNa3b99G69at8emnn5p9vjCf7+TJk7F+/XqsXr0au3btQlJSEvr374/MzMyyuo0iy+++k5OTcejQIcyePRuHDh3CunXrcOrUKQwcODDXuU8++aTJ38Dnn39eFs0vtoI+b6Dgv+uK9nkDMLnf6OhorFixAjqdDg899JDJeeXq81aoTNx1113KhAkTTI41adJEmTFjhpVaVPpiYmIUAMr27dsNx8aMGaMMGjTIeo0qBa+99prSunVrs89lZWUp/v7+yttvv204dufOHaVSpUrKkiVLyqiFZeP5559X6tevr2RlZSmKUjE/awDK+vXrDY8L8/nGx8crTk5OyurVqw3nXL58WdHr9coff/xRZm0viZz3bc7ff/+tAFAuXLhgONa9e3fl+eefL93GlSJz913Q37W9fN6DBg1SevbsaXKsvH3ezACVgbS0NBw8eBAhISEmx0NCQrBnzx4rtar03bp1CwBQpUoVk+Pbtm1D9erV0ahRIzz55JOIiYmxRvMs6vTp06hRowbq1q2Lxx57DOfOnQMAREZG4urVqyafvYuLC7p3716hPvu0tDR8++23GDdunMkCwhXxszZWmM/34MGDSE9PNzmnRo0aaNGiRYX6G7h16xZ0Oh18fHxMjn/33XeoVq0amjdvjmnTppX7zCeQ/9+1PXze165dw8aNG/HEE0/keq48fd5cDLUMxMbGIjMzE35+fibH/fz8cPXqVSu1qnQpioKpU6finnvuQYsWLQzH+/Tpg0ceeQR16tRBZGQkZs+ejZ49e+LgwYPldmbRjh074uuvv0ajRo1w7do1vPHGG+jcuTOOHz9u+HzNffYXLlywRnNLxYYNGxAfH4+xY8cajlXEzzqnwny+V69ehbOzMypXrpzrnIry3/+dO3cwY8YMDB8+3GSBzBEjRqBu3brw9/fHsWPHMHPmTBw5csTQXVoeFfR3bQ+f91dffQUvLy8MGTLE5Hh5+7wZAJUh438ZAxIk5DxWUTzzzDP4999/sWvXLpPjQ4cONey3aNEC7du3R506dbBx48Zc/zGVF3369DHst2zZEp06dUL9+vXx1VdfGYojK/pnv3z5cvTp0wc1atQwHKuIn3VeivP5VpS/gfT0dDz22GPIysrCokWLTJ578sknDfstWrRAw4YN0b59exw6dAjt2rUr66ZaRHH/rivK5w0AK1aswIgRI+Dq6mpyvLx93uwCKwPVqlWDg4NDrug/JiYm178cK4Jnn30Wv/zyC7Zu3YpatWrle25AQADq1KmD06dPl1HrSp+HhwdatmyJ06dPG0aDVeTP/sKFC9i8eTPGjx+f73kV8bMuzOfr7++PtLQ0xMXF5XlOeZWeno5HH30UkZGRCAsLM8n+mNOuXTs4OTlVqL+BnH/XFfnzBoCdO3fi5MmTBf73Dtj+580AqAw4OzsjODg4VxowLCwMnTt3tlKrLE9RFDzzzDNYt24dtmzZgrp16xb4mhs3buDixYsICAgogxaWjdTUVERERCAgIMCQDjb+7NPS0rB9+/YK89l/+eWXqF69Ovr165fveRXxsy7M5xscHAwnJyeTc6Kjo3Hs2LFy/TegBj+nT5/G5s2bUbVq1QJfc/z4caSnp1eov4Gcf9cV9fNWLV++HMHBwWjdunWB59r8523FAmy7snr1asXJyUlZvny5cuLECWXy5MmKh4eHcv78eWs3zWKefvpppVKlSsq2bduU6Ohow09ycrKiKIqSmJiovPDCC8qePXuUyMhIZevWrUqnTp2UmjVrKgkJCVZuffG98MILyrZt25Rz584p+/btU/r37694eXkZPtu3335bqVSpkrJu3Trl6NGjyrBhw5SAgIByfc+qzMxMpXbt2spLL71kcrwifdaJiYnK4cOHlcOHDysAlA8//FA5fPiwYbRTYT7fCRMmKLVq1VI2b96sHDp0SOnZs6fSunVrJSMjw1q3VaD87js9PV0ZOHCgUqtWLSU8PNzkv/fU1FRFURTlzJkzyty5c5UDBw4okZGRysaNG5UmTZoobdu2Lbf3Xdi/64r2eatu3bqluLu7K4sXL871+vL4eTMAKkOfffaZUqdOHcXZ2Vlp166dyfDwigCA2Z8vv/xSURRFSU5OVkJCQhRfX1/FyclJqV27tjJmzBglKirKug0voaFDhyoBAQGKk5OTUqNGDWXIkCHK8ePHDc9nZWUpr732muLv76+4uLgo3bp1U44ePWrFFlvOn3/+qQBQTp48aXK8In3WW7duNft3PWbMGEVRCvf5pqSkKM8884xSpUoVxc3NTenfv7/N/y7yu+/IyMg8/3vfunWroiiKEhUVpXTr1k2pUqWK4uzsrNSvX1957rnnlBs3blj3xgqQ330X9u+6on3eqs8//1xxc3NT4uPjc72+PH7eOkVRlFJNMRERERHZGNYAERERkd1hAERERER2hwEQERER2R0GQERERGR3GAARERGR3WEARERERHaHARARERHZHQZAREREZHcYABERmbFt2zbodDrEx8dbuylEVAoYABEREZHdYQBEREREdocBEBHZJEVR8O6776JevXpwc3ND69at8dNPPwHQuqc2btyI1q1bw9XVFR07dsTRo0dNrrF27Vo0b94cLi4uCAoKwgcffGDyfGpqKl588UUEBgbCxcUFDRs2xPLly03OOXjwINq3bw93d3d07twZJ0+eNDx35MgR9OjRA15eXvD29kZwcDD++eefUvqNEJElOVq7AURE5rzyyitYt24dFi9ejIYNG2LHjh0YOXIkfH19DedMnz4dCxcuhL+/P15++WUMHDgQp06dgpOTEw4ePIhHH30Uc+bMwdChQ7Fnzx5MnDgRVatWxdixYwEAo0ePxt69e/Hxxx+jdevWiIyMRGxsrEk7Zs2ahQ8++AC+vr6YMGECxo0bh927dwMARowYgbZt22Lx4sVwcHBAeHg4nJycyux3REQlYOXV6ImIcklKSlJcXV2VPXv2mBx/4oknlGHDhilbt25VACirV682PHfjxg3Fzc1NWbNmjaIoijJ8+HClV69eJq+fPn260qxZM0VRFOXkyZMKACUsLMxsG9T32Lx5s+HYxo0bFQBKSkqKoiiK4uXlpaxcubLkN0xEZY5dYERkc06cOIE7d+6gV69e8PT0NPx8/fXXOHv2rOG8Tp06GfarVKmCxo0bIyIiAgAQERGBLl26mFy3S5cuOH36NDIzMxEeHg4HBwd0794937a0atXKsB8QEAAAiImJAQBMnToV48ePx/3334+3337bpG1EZNsYABGRzcnKygIAbNy4EeHh4YafEydOGOqA8qLT6QBIDZG6r1IUxbDv5uZWqLYYd2mp11PbN2fOHBw/fhz9+vXDli1b0KxZM6xfv75Q1yUi62IAREQ2p1mzZnBxcUFUVBQaNGhg8hMYGGg4b9++fYb9uLg4nDp1Ck2aNDFcY9euXSbX3bNnDxo1agQHBwe0bNkSWVlZ2L59e4na2qhRI0yZMgWbNm3CkCFD8OWXX5boekRUNlgETUQ2x8vLC9OmTcOUKVOQlZWFe+65BwkJCdizZw88PT1Rp04dAMC8efNQtWpV+Pn5YdasWahWrRoGDx4MAHjhhRfQoUMHvP766xg6dCj27t2LTz/9FIsWLQIABAUFYcyYMRg3bpyhCPrChQuIiYnBo48+WmAbU1JSMH36dDz88MOoW7cuLl26hAMHDuChhx4qtd8LEVmQtYuQiIjMycrKUhYuXKg0btxYcXJyUnx9fZXevXsr27dvNxQo//rrr0rz5s0VZ2dnpUOHDkp4eLjJNX766SelWbNmipOTk1K7dm3lvffeM3k+JSVFmTJlihIQEKA4OzsrDRo0UFasWKEoilYEHRcXZzj/8OHDCgAlMjJSSU1NVR577DElMDBQcXZ2VmrUqKE888wzhgJpIrJtOkUx6hQnIioHtm3bhh49eiAuLg4+Pj7Wbg4RlUOsASIiIiK7wwCIiIiI7A67wIiIiMjuMANEREREdocBEBEREdkdBkBERERkdxgAERERkd1hAERERER2hwEQERER2R0GQERERGR3GAARERGR3fk/yU5t4TSL6XkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'], c='red', label='train loss')\n",
    "ax.plot(history.history['val_loss'], c='blue', label='vailidation loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('error')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_wine_model_0203.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imported = keras.models.load_model('best_wine_model_0203.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/step - loss: 0.0678 - acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0677850991487503, 0.9810256361961365]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_imported.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True) # uint8은 부호없는 정수이기 때문에 float로 변경 작업 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) float64\n",
      "(10000, 784) float64\n",
      "(60000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "## dimension (3차원을 2차원으로 바꿀 필요가 있음)\n",
    "\n",
    "X_train_784 = (X_train/255.).reshape(-1, 28 * 28) # divide 할 때 . 써주면 float 타입으로 자동 적용\n",
    "X_test_784 = (X_test/255.).reshape(-1, 28 * 28) # divide 할 때 . 써주면 float 타입으로 자동 적용\n",
    "print(X_train_784.shape, X_train_784.dtype)\n",
    "print(X_test_784.shape, X_test_784.dtype)\n",
    "\n",
    "## y-onehot 인코딩\n",
    "y_train_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_hot = keras.utils.to_categorical(y_test)\n",
    "print(y_train_hot.shape)\n",
    "print(y_train_hot[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 (DNN, Dense Neural  Network)\n",
    "[DNN이란](http://www.tcpschool.com/deeplearning/deep_algorithm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_784\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 512)               401920    \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='mnist_784')\n",
    "model.add(keras.layers.Dense(512, input_shape=(784, ), activation='relu', name='hidden'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='output')) # 카테고리가 10개니까 노드 10개(0~9 확인)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.3497 - acc: 0.9040\n",
      "Epoch 1: val_loss improved from inf to 0.19476, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 2s 5ms/step - loss: 0.3451 - acc: 0.9052 - val_loss: 0.1948 - val_acc: 0.9441\n",
      "Epoch 2/1000\n",
      "207/210 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9578\n",
      "Epoch 2: val_loss improved from 0.19476 to 0.14039, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.1470 - acc: 0.9577 - val_loss: 0.1404 - val_acc: 0.9583\n",
      "Epoch 3/1000\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0994 - acc: 0.9715\n",
      "Epoch 3: val_loss improved from 0.14039 to 0.11890, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0994 - acc: 0.9715 - val_loss: 0.1189 - val_acc: 0.9646\n",
      "Epoch 4/1000\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9800\n",
      "Epoch 4: val_loss improved from 0.11890 to 0.10563, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0717 - acc: 0.9800 - val_loss: 0.1056 - val_acc: 0.9695\n",
      "Epoch 5/1000\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9841\n",
      "Epoch 5: val_loss improved from 0.10563 to 0.09751, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0550 - acc: 0.9843 - val_loss: 0.0975 - val_acc: 0.9712\n",
      "Epoch 6/1000\n",
      "200/210 [===========================>..] - ETA: 0s - loss: 0.0416 - acc: 0.9887\n",
      "Epoch 6: val_loss improved from 0.09751 to 0.09724, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0416 - acc: 0.9886 - val_loss: 0.0972 - val_acc: 0.9702\n",
      "Epoch 7/1000\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.0319 - acc: 0.9922\n",
      "Epoch 7: val_loss improved from 0.09724 to 0.09533, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0319 - acc: 0.9921 - val_loss: 0.0953 - val_acc: 0.9717\n",
      "Epoch 8/1000\n",
      "203/210 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9945\n",
      "Epoch 8: val_loss improved from 0.09533 to 0.09002, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0243 - acc: 0.9944 - val_loss: 0.0900 - val_acc: 0.9734\n",
      "Epoch 9/1000\n",
      "199/210 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9961\n",
      "Epoch 9: val_loss improved from 0.09002 to 0.08652, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0198 - acc: 0.9960 - val_loss: 0.0865 - val_acc: 0.9748\n",
      "Epoch 10/1000\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9975\n",
      "Epoch 10: val_loss improved from 0.08652 to 0.08369, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0145 - acc: 0.9975 - val_loss: 0.0837 - val_acc: 0.9751\n",
      "Epoch 11/1000\n",
      "206/210 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9985\n",
      "Epoch 11: val_loss improved from 0.08369 to 0.08125, saving model to ./model\\mnist_784.hdf5\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0111 - acc: 0.9985 - val_loss: 0.0812 - val_acc: 0.9755\n",
      "Epoch 12/1000\n",
      "203/210 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9989\n",
      "Epoch 12: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0091 - acc: 0.9989 - val_loss: 0.0894 - val_acc: 0.9751\n",
      "Epoch 13/1000\n",
      "209/210 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9992\n",
      "Epoch 13: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0074 - acc: 0.9992 - val_loss: 0.0857 - val_acc: 0.9763\n",
      "Epoch 14/1000\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9997\n",
      "Epoch 14: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0053 - acc: 0.9997 - val_loss: 0.0866 - val_acc: 0.9768\n",
      "Epoch 15/1000\n",
      "203/210 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9998\n",
      "Epoch 15: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0852 - val_acc: 0.9772\n",
      "Epoch 16/1000\n",
      "195/210 [==========================>...] - ETA: 0s - loss: 0.0031 - acc: 0.9999\n",
      "Epoch 16: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0031 - acc: 0.9999 - val_loss: 0.0843 - val_acc: 0.9771\n",
      "Epoch 17/1000\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.0025 - acc: 0.9999\n",
      "Epoch 17: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0880 - val_acc: 0.9772\n",
      "Epoch 18/1000\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 0.9778\n",
      "Epoch 19/1000\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9777\n",
      "Epoch 20/1000\n",
      "206/210 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 0.9773\n",
      "Epoch 21/1000\n",
      "201/210 [===========================>..] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.08125\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9779\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='acc')\n",
    "\n",
    "model_path = './model/mnist_784.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train_784, y_train_hot, epochs=1000, batch_size=200, validation_split=0.3, callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0727 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07269196212291718, 0.9811000227928162]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_784, y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'], c='red', label='train loss')\n",
    "ax.plot(history.history['val_loss'], c='blue', label='val loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('error')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train/255.).reshape(-1, 28, 28, 1) # 마지막이 1인 이유? 흑백이라서..\n",
    "X_test = (X_test/255.).reshape(-1, 28, 28, 1)\n",
    "# y_train_hot\n",
    "# y_test_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name='mnist_cnn')\n",
    "model.add(keras.layers.Conv2D(32, input_shape = (28, 28, 1), kernel_size = (3,3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.2905 - acc: 0.9096\n",
      "Epoch 1: val_loss improved from inf to 0.07394, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 19s 87ms/step - loss: 0.2905 - acc: 0.9096 - val_loss: 0.0739 - val_acc: 0.9790\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.9765\n",
      "Epoch 2: val_loss improved from 0.07394 to 0.05512, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 18s 88ms/step - loss: 0.0758 - acc: 0.9765 - val_loss: 0.0551 - val_acc: 0.9840\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0504 - acc: 0.9844\n",
      "Epoch 3: val_loss improved from 0.05512 to 0.04886, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 18s 83ms/step - loss: 0.0504 - acc: 0.9844 - val_loss: 0.0489 - val_acc: 0.9858\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9879\n",
      "Epoch 4: val_loss improved from 0.04886 to 0.04722, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 18s 84ms/step - loss: 0.0385 - acc: 0.9879 - val_loss: 0.0472 - val_acc: 0.9861\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9906\n",
      "Epoch 5: val_loss improved from 0.04722 to 0.04468, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 18s 84ms/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0447 - val_acc: 0.9872\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 6: val_loss did not improve from 0.04468\n",
      "210/210 [==============================] - 18s 85ms/step - loss: 0.0247 - acc: 0.9917 - val_loss: 0.0512 - val_acc: 0.9867\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 7: val_loss did not improve from 0.04468\n",
      "210/210 [==============================] - 18s 85ms/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0458 - val_acc: 0.9884\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0179 - acc: 0.9937\n",
      "Epoch 8: val_loss did not improve from 0.04468\n",
      "210/210 [==============================] - 23s 111ms/step - loss: 0.0179 - acc: 0.9937 - val_loss: 0.0470 - val_acc: 0.9879\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9947\n",
      "Epoch 9: val_loss did not improve from 0.04468\n",
      "210/210 [==============================] - 23s 111ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0513 - val_acc: 0.9869\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9951\n",
      "Epoch 10: val_loss did not improve from 0.04468\n",
      "210/210 [==============================] - 24s 114ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0542 - val_acc: 0.9873\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9957\n",
      "Epoch 11: val_loss improved from 0.04468 to 0.04229, saving model to ./model\\mnist_best_cnn.hdf5\n",
      "210/210 [==============================] - 24s 112ms/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0423 - val_acc: 0.9892\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9962\n",
      "Epoch 12: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 23s 112ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.0494 - val_acc: 0.9894\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.9970\n",
      "Epoch 13: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 23s 111ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0466 - val_acc: 0.9891\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 14: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 23s 112ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0495 - val_acc: 0.9893\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9964\n",
      "Epoch 15: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 24s 116ms/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.0503 - val_acc: 0.9886\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 16: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 27s 129ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0539 - val_acc: 0.9888\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9968\n",
      "Epoch 17: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 25s 119ms/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0597 - val_acc: 0.9880\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9976\n",
      "Epoch 18: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 25s 118ms/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0514 - val_acc: 0.9892\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 19: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 29s 137ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0560 - val_acc: 0.9897\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9975\n",
      "Epoch 20: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 24s 115ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0584 - val_acc: 0.9881\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 21: val_loss did not improve from 0.04229\n",
      "210/210 [==============================] - 25s 121ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0549 - val_acc: 0.9892\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0400 - acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04000396281480789, 0.9891999959945679]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='acc')\n",
    "model_path='./model/mnist_best_cnn.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, verbose=1, save_best_only=True)\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train, y_train_hot, validation_split=0.3, epochs=100, batch_size=200, callbacks=[checkpoint,earlystop])\n",
    "\n",
    "model.evaluate(X_test, y_test_hot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN 오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 6272)              633472    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 6272)             25088     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        204864    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 1)         1601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 865,281\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 생성자 모델\n",
    "generator = keras.Sequential()\n",
    "generator.add(keras.layers.Dense(128*7*7, input_shape=(100, ), activation='linear'))\n",
    "generator.add(keras.layers.BatchNormalization())\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.Reshape((7,7,128)))\n",
    "generator.add(keras.layers.UpSampling2D())\n",
    "generator.add(keras.layers.Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(keras.layers.BatchNormalization())\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.UpSampling2D())\n",
    "generator.add(keras.layers.Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 0\n",
      "Non-trainable params: 212,865\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 판별자 생성\n",
    "discriminator = keras.Sequential()\n",
    "discriminator.add(keras.layers.Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding='same', activation='relu'))\n",
    "discriminator.add(keras.layers.Activation(keras.layers.LeakyReLU(0.2)))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Conv2D(128, kernel_size=5, strides=2, padding='same', activation='relu'))\n",
    "discriminator.add(keras.layers.Flatten())\n",
    "discriminator.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_10 (Sequential)  (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_12 (Sequential)  (None, 1)                 212865    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## 생성자와 판별자를 연결\n",
    "ginput = keras.layers.Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = keras.models.Model(ginput, dis_output)\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    (X_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.reshape(-1,28,28,1)\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "\n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for i in range(epoch):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "        noise = np.random.normal()\n",
    "        gen_images = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_images, fake)\n",
    "\n",
    "        d_loss = 0.5 * (d_loss_fake + d_loss_real)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "        if i % saving_interval == 0:\n",
    "            noise = np.random.normal(0,1,(25,100))\n",
    "            gen_images = generator.predict(noise)\n",
    "\n",
    "            gen_images = 0.5 * gen_images + 0.5\n",
    "\n",
    "            fig, ax = plt.subplots(5,5)\n",
    "            count = 0\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    ax[j, k].imshow(gen_images[count, :,:,0], cmap='gray')\n",
    "                    ax[j, k].axis('off')\n",
    "                    count += 1\n",
    "            fig.savefig('./gan_image_{}'.format(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c381a02c790371f446e82335a49413d76a5d4066b7efd29c82f48d4ece28e467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
